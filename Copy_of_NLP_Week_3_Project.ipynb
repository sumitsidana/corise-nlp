{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sumitsidana/corise-nlp/blob/main/Copy_of_NLP_Week_3_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOTJFRLT5i1Y"
      },
      "source": [
        "> DUPLICATE THIS COLAB TO START WORKING ON IT. Using File > Save a copy to drive.\n",
        "\n",
        "\n",
        "# Week 3: Embedding-Based Retrieval\n",
        "\n",
        "### What we are building\n",
        "The goal of Embedding-Based Retrieval is to retrieve top-k candidates given a query based on embedding similarity/distance. A common application for this is given a query/sentence/document, find top-k similar candidates wrt query. While this is usually solved using TF-IDF/Information Retrieval (IR) based approaches, it is becoming more and more common in the industry to use an embedding based approach: encode the query and document as an embedding and use approximate nearest neighbor search to find top-k candidates in real-time.\n",
        "\n",
        "We will build a system to find duplicate questions on Quora using a [dataset released by Quora](https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs). A very common problem for forums/QA websites is trying to determine whether a question has already been asked before a user posts it.\n",
        "\n",
        "We will continue to apply our learning philosophy of repetition as we build multiple models of increasing complexity in the following order:\n",
        "\n",
        "1. Retrieval based on WordVectors\n",
        "1. Using BERT\n",
        "1. Using Sentence BERT\n",
        "1. Using Cohere Sentence Embeddings\n",
        "\n",
        "###  Evaluation\n",
        "We will evaluate our models along the following metrics: \n",
        "\n",
        "1. Recall@k: the proportion of relevant items found in the top-k matches\n",
        "1. Mean Reciprocal Rank: the rank of the first relevant item with respect to the top-k.\n",
        "\n",
        "### Instructions\n",
        "\n",
        "1. We have provide scaffolding for all the boiler plate Faiss code to get to our baseline model. This covers downloading and parsing the dataset, and training code for the baseline model. **Make sure to read all the steps and internalize what is happening**.\n",
        "1. At this point in our model, we will aim to use BERT embeddings. **Does this improve accuracy?**\n",
        "1. In the third model, we will use Sentence BERT and then we'll see if they can boost up our model. **How do you think this model will perform?**\n",
        "1. **Extension**: We have suggested a bunch of extensions to the project so go crazy! Tweak any parts of the pipeline, and see if you can beat all the current modes.\n",
        "\n",
        "### Code Overview\n",
        "\n",
        "- Dependencies: Install and import python dependencies\n",
        "- Project\n",
        "  - Dataset: Download the Quora dataset\n",
        "  - Indexer: Function to manage and create a Faiss Index\n",
        "  - Model 1: Word Vectors\n",
        "  - Model 2: BERT\n",
        "  - Model 3: Sentence BERT\n",
        "  - Model 4: Cohere Sentence Embeddings\n",
        "- Extensions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8zLCEfd7VKI"
      },
      "source": [
        "# Dependencies\n",
        "\n",
        "✨ Now let's get started! To kick things off, as always, we will install some dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajhbV2UD5UGd"
      },
      "source": [
        "%%capture\n",
        "# Install all the required dependencies for the project\n",
        "!pip install pytorch-lightning==1.6.5\n",
        "!pip install spacy==2.2.4\n",
        "!python -m spacy download en_core_web_md\n",
        "!apt install libopenblas-base libomp-dev\n",
        "!pip install faiss==1.5.3\n",
        "!pip install faiss-cpu\n",
        "!pip install -U sentence-transformers\n",
        "!pip install transformers==4.17.0\n",
        "#!pip install sentence-transformers==2.2.0\n",
        "!pip install cohere"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTWZJAqiBxEv"
      },
      "source": [
        "Import all the necessary libraries we need throughout the project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esA3TFU2-9dI"
      },
      "source": [
        "# Import all the relevant libraries\n",
        "import csv\n",
        "import en_core_web_md\n",
        "import faiss\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "import random\n",
        "import spacy\n",
        "import torch\n",
        "import cohere\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from torch.nn import functional as F\n",
        "from transformers import BertTokenizer, BertModel, BertTokenizerFast, DistilBertTokenizer, DistilBertModel\n",
        "from limit import limit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWE7zx6Wnria"
      },
      "source": [
        "Now let's load the Spacy data, which comes with pre-trainined embeddings. This process is expensive so only do it once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BhsykZdEK2m6"
      },
      "source": [
        "# Really expensive operation to load the entire space word-vector index in memory\n",
        "# We'll only run it once \n",
        "loaded_spacy_model = en_core_web_md.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiXEUsahCJeA"
      },
      "source": [
        "# Embedding Based Retrieval\n",
        "\n",
        "✨ Let's Begin ✨"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFcN6rKkCQiu"
      },
      "source": [
        "### Data Loading and Processing (Common to ALL Solutions)\n",
        "\n",
        "#### Dataset\n",
        "\n",
        "Download the duplicate questions [dataset released by Quora](https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTXv0v34AYOU"
      },
      "source": [
        "%%capture\n",
        "!wget 'http://qim.fs.quoracdn.net/quora_duplicate_questions.tsv'\n",
        "!mkdir qqp\n",
        "!mv quora_duplicate_questions.tsv qqp/\n",
        "!ls qqp/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjVbbS-CucF0"
      },
      "source": [
        "Perfect. Now we see all of our files. Let's poke at one of them before we start parsing our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-MUggjUui6y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "901debc0-c60a-448a-a400-3e39565a35b1"
      },
      "source": [
        "DATA_FILE = \"qqp/quora_duplicate_questions.tsv\"\n",
        "\n",
        "# The file is a 6-column tab separated file. \n",
        "# The first column is the row_id, second and third questions are ids of \n",
        "# specific questions, followed by the text of questions.\n",
        "# The last column captures if the two questions are duplicates\n",
        "with open(DATA_FILE, 'r', newline='\\n') as file:\n",
        "  reader = csv.reader(file, delimiter = '\\t')\n",
        "  # Read first 10 lines\n",
        "  for i in range(10):\n",
        "    print(next(reader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate']\n",
            "['0', '1', '2', 'What is the step by step guide to invest in share market in india?', 'What is the step by step guide to invest in share market?', '0']\n",
            "['1', '3', '4', 'What is the story of Kohinoor (Koh-i-Noor) Diamond?', 'What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?', '0']\n",
            "['2', '5', '6', 'How can I increase the speed of my internet connection while using a VPN?', 'How can Internet speed be increased by hacking through DNS?', '0']\n",
            "['3', '7', '8', 'Why am I mentally very lonely? How can I solve it?', 'Find the remainder when [math]23^{24}[/math] is divided by 24,23?', '0']\n",
            "['4', '9', '10', 'Which one dissolve in water quikly sugar, salt, methane and carbon di oxide?', 'Which fish would survive in salt water?', '0']\n",
            "['5', '11', '12', 'Astrology: I am a Capricorn Sun Cap moon and cap rising...what does that say about me?', \"I'm a triple Capricorn (Sun, Moon and ascendant in Capricorn) What does this say about me?\", '1']\n",
            "['6', '13', '14', 'Should I buy tiago?', 'What keeps childern active and far from phone and video games?', '0']\n",
            "['7', '15', '16', 'How can I be a good geologist?', 'What should I do to be a great geologist?', '1']\n",
            "['8', '17', '18', 'When do you use シ instead of し?', 'When do you use \"&\" instead of \"and\"?', '0']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5uNuyGSxRql"
      },
      "source": [
        "The dataset has more than 500k questions! We are going to parse the full dataset and create a sample of 10k questions to experiment with in our models since BERT training & inference can be really slow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_mRCola0s8z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74baa669-1617-4b46-d3f2-7ccac414fbbe"
      },
      "source": [
        "\"\"\"\n",
        "Util function to parse the file\n",
        "\"\"\"\n",
        "def parse_sample_dataset(file_path, sample_max_id):\n",
        "  \"\"\"\n",
        "  Inputs:\n",
        "    file_path: Path to the raw data file\n",
        "    sample_max_id: Max question id to be considered in the sampled dataset\n",
        "\n",
        "  Returns 4 objects:\n",
        "    1. QuestionMap: list of all question ids\n",
        "    2. DuplicatesMap: Map of questionID to it's duplicates\n",
        "    3. SampleDataset: list of questionIds in the sample\n",
        "    4. SampleEvalDataset: list of pair of duplicate questions in the sample\n",
        "  \"\"\"\n",
        "  question_map = {}\n",
        "  duplicates_map = defaultdict(set)\n",
        "  sample_dataset = set([])\n",
        "  sample_eval_dataset = []\n",
        "\n",
        "  with open(file_path, 'r', newline='\\n') as file:\n",
        "    reader = csv.reader(file, delimiter='\\t')\n",
        "    next(reader)  # Skip the header line\n",
        "\n",
        "    for row in reader:\n",
        "      if len(row) != 6: # Skip incomplete rows\n",
        "        continue\n",
        "\n",
        "      # Limit the sample size of the dataset at max_id\n",
        "      # Make sure all 4 objects start at index 0\n",
        "      qid1, qid2, label = int(row[1]) - 1, int(row[2]) - 1, int(row[5])\n",
        "      if qid1 < sample_max_id and qid2 < sample_max_id:\n",
        "        \n",
        "        if qid1 not in question_map:\n",
        "          question_map[qid1] = str(row[3])\n",
        "        if qid2 not in question_map:\n",
        "          question_map[qid2] = str(row[4])\n",
        "\n",
        "        if label == 1:\n",
        "          duplicates_map[qid1].add(qid2)\n",
        "          duplicates_map[qid2].add(qid1)\n",
        "\n",
        "          sample_eval_dataset.append((qid1, qid2))\n",
        "\n",
        "        sample_dataset.add(qid1)\n",
        "        sample_dataset.add(qid2)\n",
        "\n",
        "  # sample dataset duplicates removed via set(), so turn back into list\n",
        "  return question_map, duplicates_map, list(sample_dataset), sample_eval_dataset\n",
        "\n",
        "question_map, duplicates_map, sample_dataset, sample_eval_dataset, = parse_sample_dataset(DATA_FILE, 10000)\n",
        "\n",
        "# Complete file: 537k unique questions, 400k duplicate.\n",
        "# To keep training time manageable limited to 10.000 (sample_max_id)\n",
        "print(\"Number of unique questions:\", len(question_map)) # 10.000\n",
        "print(\"Number of question with duplicates:\", len(duplicates_map)) # ~3.8k\n",
        "print(\"Number of questions in sample:\", len(sample_dataset)) # 10.000\n",
        "print(\"Number of duplicate pairs in sample:\", len(sample_eval_dataset)) # ~3.6k"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique questions: 10000\n",
            "Number of question with duplicates: 3810\n",
            "Number of questions in sample: 10000\n",
            "Number of duplicate pairs in sample: 3589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tC9D41185-Oa"
      },
      "source": [
        "# Retrieval using Faiss -- TO BE COMPLETED\n",
        "\n",
        "You are now going to create an Indexer class that implements multiple functions for indexing, searching, and evaluating our retrieval model. Faiss documentation can be found in the wiki here: https://github.com/facebookresearch/faiss/wiki/Getting-started\n",
        "\n",
        "Some helpful Faiss guides are:\n",
        "- https://www.pinecone.io/learn/faiss-tutorial/\n",
        "- https://www.pinecone.io/learn/vector-indexes/\n",
        "\n",
        "You need to implement the following functions:\n",
        "\n",
        "1. **search**: Implement a function that takes a question and top_k variable and returns either the matched strings or the ids to the user as a \n",
        "    1. Call the search API on the faiss_index to look up similar sentences using `faiss_index.search`\n",
        "    2. Parse the output to either return [sentence_id, score] tuples or [sentence, score] tuples based on the input parameter\n",
        "    3. Sort the output by the score in descending order\n",
        "\n",
        "1. **evaluate**: Sample num_docs pairs from the evaluation dataset and then check if the qid2 is present in the top-k results\n",
        "    1. For each eval sample, find the top_k matches for the qid1\n",
        "    2. See if the qid2 is in one of the matches\n",
        "    3. If yes, append (1) to the recall array otherwise append (0)\n",
        "    4. Implement MRR (Mean reciprocal rank) addition based on the position of qid2 in matches.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji7yyBk5Ou6k"
      },
      "source": [
        "class FaissIndexer:\n",
        "  def __init__(self, dataset,\n",
        "               question_map, \n",
        "               eval_dataset, \n",
        "               batch_size, \n",
        "               sentence_vector_dim, \n",
        "               vectorizer):\n",
        "    self.question_map = question_map\n",
        "    self.dataset = dataset\n",
        "    self.eval_dataset = eval_dataset\n",
        "    self.batch_size = batch_size\n",
        "    self.vectorizer = vectorizer\n",
        "    # FlatIP uses inner product\n",
        "    self.faiss_index = faiss.IndexFlatIP(sentence_vector_dim)\n",
        "\n",
        "\n",
        "  def split_list(self, lst: list, sublist_size: int):\n",
        "    sublists = []\n",
        "    # Split lst into even chunks/sublists/batches\n",
        "    for i in range(0, len(lst), sublist_size): \n",
        "        sublists.append(lst[i:i + sublist_size])\n",
        "    return sublists\n",
        "\n",
        "\n",
        "  def index(self):\n",
        "    sentence_vectors = []\n",
        "\n",
        "    print(\"Start indexing!\")\n",
        "    for sentence_ids in tqdm(self.split_list(self.dataset, self.batch_size)):\n",
        "      # Retrieve sentences based on qid\n",
        "      sentences = [question_map[qid] for qid in sentence_ids]\n",
        "      # Get embeddings of the sentences (Spacy, ..., Cohere)\n",
        "      sentence_vectors_batch = self.vectorizer.vectorize(sentences)\n",
        "      # Add batch to temporary list\n",
        "      sentence_vectors.append(sentence_vectors_batch)\n",
        "\n",
        "    # Add all batches from temporary list to index\n",
        "    self.faiss_index.add(np.array(np.concatenate(sentence_vectors, axis=0)))\n",
        "    print(\"\\nDone indexing!\")\n",
        "\n",
        "\n",
        "  def search(self, question: str, top_k: int, return_ids=False):\n",
        "    \"\"\"Given any sentence (typed by the user)\n",
        "    We return a list of top_k(sentence, sim_score) or top_k(sentence_ids, sim_score)\n",
        "    \n",
        "    NOTE: The output type is controlled by the return_ids flag\n",
        "\n",
        "    1. Call the search API on the faiss_index to look up similar sentences \n",
        "       using `faiss_index.search`\n",
        "    2. Parse the output to either return [sentence_id, score] tuples or \n",
        "       [sentence, score] tuples based on return_ids being true/false\n",
        "    3. Sort the output by the score in descending order\n",
        "    \"\"\"\n",
        "\n",
        "    # NOTE: We converted the question to a list here to match the signature \n",
        "    # of the vectorize function\n",
        "    question_vectors = self.vectorizer.vectorize([question])\n",
        "\n",
        "    ### TO BE IMPLEMENTED ###\n",
        "    scores, indices = self.faiss_index.search(np.float32(np.array(question_vectors)), top_k)\n",
        "    # print(scores)\n",
        "    # print(indices)\n",
        "    # sort the results in descending order of scores\n",
        "    indices_list =[]\n",
        "    sentences_indices_list = []\n",
        "\n",
        "    if return_ids:\n",
        "      for indice, score in zip(indices[0], scores[0]):\n",
        "        pair = (indice, score)\n",
        "        indices_list.append(pair)\n",
        "      output = indices_list\n",
        "    else:\n",
        "      for indice, score in zip(indices[0], scores[0]):\n",
        "        pair = (self.dataset[indice], score)\n",
        "        sentences_indices_list.append(pair)\n",
        "      output = sentences_indices_list\n",
        "\n",
        "    ### TO BE IMPLEMENTED ###\n",
        "\n",
        "    \n",
        "\n",
        "    # Output is a List[(qid, score), (qid, score), (qid, score)] or \n",
        "    # List[(q, score), (q, score), (q, score)] based on return_ids\n",
        "    # Output is sorted in descending order of score\n",
        "    # print(output)\n",
        "    return output\n",
        "\n",
        "\n",
        "  def evaluate(self, top_k: int, eval_sample_size: int):\n",
        "    \"\"\"Sample num_docs pairs from the evaluation dataset and then check \n",
        "    if the qid2 is present in the top-k results\n",
        "\n",
        "    1. For each eval sample, find the top_k matches for the qid1\n",
        "    2. See if the qid2 is in one of the matches\n",
        "    3. If yes, append (1) to the recall array otherwise append (0)\n",
        "    4. Implement MRR (Mean reciprocal rank) addition based on the position of qid2 in matches\n",
        "      - Note: MRR is equivalent to mean([1/r or 0 for each sample])\n",
        "    \"\"\"\n",
        "    # Sample from evaluation dataset as proxy for performance metrics\n",
        "    eval_sample = random.sample(self.eval_dataset, eval_sample_size)\n",
        "    print(eval_sample)\n",
        "\n",
        "    # Retrieval metrics which only care about if searched for\n",
        "    # item is present among the results.\n",
        "    recall_at_k = [] # Relevant items vs total of relevant items\n",
        "    mean_reciprocal_rank = [] # Rank of the first relevant item\n",
        "\n",
        "    ### TO BE IMPLEMENTED ### \n",
        "    for qid1, qid2 in eval_sample:\n",
        "        # Find top k matches for qid1\n",
        "        query = self.question_map[qid1]\n",
        "        results = self.search(query, top_k=top_k, return_ids=True)\n",
        "\n",
        "        # Check if qid2 is in the results\n",
        "        rank_of_first_relevant_item = -1\n",
        "        for rank, (idx, score) in enumerate(results):\n",
        "            if idx == qid2:\n",
        "                rank_of_first_relevant_item = rank\n",
        "                break\n",
        "\n",
        "        # Calculate recall@k and MRR\n",
        "        recall_at_k.append(rank_of_first_relevant_item != -1)\n",
        "        if rank_of_first_relevant_item != -1:\n",
        "            reciprocal_rank = 1 / (rank_of_first_relevant_item + 1)\n",
        "            mean_reciprocal_rank.append(reciprocal_rank)\n",
        "        else:\n",
        "            mean_reciprocal_rank.append(0)\n",
        "    \n",
        "    recall_at_k = np.array(recall_at_k, dtype=np.float32)\n",
        "    # print(mean_reciprocal_rank)\n",
        "    # mean_reciprocal_rank = np.mean(mean_reciprocal_rank)\n",
        "\n",
        "    ### TO BE IMPLEMENTED ###\n",
        "\n",
        "    print(\"\\nRecall@{}:\\t\\t{:0.2f}%\".format(top_k, np.mean(np.array(recall_at_k) * 100.0)))\n",
        "    print(\"Mean Reciprocal Rank:\\t{:0.5f}\".format(np.mean(np.array(mean_reciprocal_rank))))\n",
        "\n",
        "\n",
        "  # Helper function to train, search and evaluate similar output from all the models created.\n",
        "  def train_and_evaluate(self, \n",
        "                         question_example: str, \n",
        "                         top_k: int = 10, \n",
        "                         eval_sample_size: int = 1000\n",
        "                         ):\n",
        "    print(\"---- Indexing ----\")\n",
        "    self.index()\n",
        "    print(\"\\n---- Search ----\")\n",
        "    results = self.search(question_example, top_k, return_ids=False)\n",
        "    print(\"Questions similar to:\", question_example)\n",
        "    for i, (q, s) in enumerate(results):\n",
        "      print(f\"{i} Question: {q} with score {s}\")\n",
        "    print(\"\\n---- Evaluation ----\")\n",
        "    self.evaluate(top_k, eval_sample_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuMWzJZjpKdW"
      },
      "source": [
        "## Dummy Model Test\n",
        "\n",
        "Really small sample of 4 sentences to make sure we can test our implementation of the FAISS search function correctly. We just project the 4 questions in a 2-d space where they are placed on the X-Axis if the word `invest` is present and on the Y-axis if `kohinoor` is present. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UmvNFIIw1eO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73e76890-2771-49d1-ef22-5f8089903cd7"
      },
      "source": [
        "dummy_ids = sample_dataset[:4]\n",
        "print(\"Questions:\")\n",
        "for i in dummy_ids:\n",
        "  print(i, \":\", question_map[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Questions:\n",
            "0 : What is the step by step guide to invest in share market in india?\n",
            "1 : What is the step by step guide to invest in share market?\n",
            "2 : What is the story of Kohinoor (Koh-i-Noor) Diamond?\n",
            "3 : What would happen if the Indian government stole the Kohinoor (Koh-i-Noor) diamond back?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x8n4UBEZpPT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb125ab5-38d9-40e3-8ec7-2f9ea761c5c3"
      },
      "source": [
        "class DummyVectorizer:\n",
        "  def __init__(self, sentence_vector_dim):\n",
        "    self.sentence_vector_dim = sentence_vector_dim\n",
        "\n",
        "  def vectorize(self, sentences):\n",
        "    \"\"\"Return sentence vectors for the batch of sentences. \n",
        "\n",
        "    1. Tokenize each sentence and create vectors for each token in the sentence\n",
        "    2. Sentence vector is the mean of word vectors of each token\n",
        "    3. Stack the sentence vectors into a numpy array using np.stack\n",
        "    \"\"\"\n",
        "    vectors = []\n",
        "    for sentence in sentences:\n",
        "      if \"invest\" in sentence:\n",
        "        # If \"invest\" is present place it on the X-Axis\n",
        "        vectors.append(np.array([random.random(), 0], dtype=np.float32))\n",
        "      elif \"Kohinoor\" in sentence:\n",
        "        # If \"Kohinoor\" is present place it on the Y-Axis\n",
        "        vectors.append(np.array([0, random.random()], dtype=np.float32))\n",
        "    return np.stack(vectors)\n",
        "\n",
        "\n",
        "di = FaissIndexer(dummy_ids, \n",
        "                  question_map,\n",
        "                  sample_eval_dataset,\n",
        "                  batch_size=1024, \n",
        "                  sentence_vector_dim=2, \n",
        "                  vectorizer=DummyVectorizer(2)\n",
        "                  )\n",
        "\n",
        "di.index()\n",
        "\n",
        "results = di.search(\"invest\", 4)\n",
        "print(\"Questions similar to:\", \"invest\")\n",
        "for i, (q, s) in enumerate(results):\n",
        "  print(f\"{i} Question: {q} with score {s}\")\n",
        "\n",
        "results = di.search(\"Kohinoor\", 4)\n",
        "print(\"\\nQuestions similar to:\", \"Kohinoor\")\n",
        "for i, (q, s) in enumerate(results):\n",
        "  print(f\"{i} Question: {q} with score {s}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start indexing!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 1947.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done indexing!\n",
            "Questions similar to: invest\n",
            "0 Question: 1 with score 0.0735018402338028\n",
            "1 Question: 0 with score 0.04226990416646004\n",
            "2 Question: 3 with score 0.0\n",
            "3 Question: 2 with score 0.0\n",
            "\n",
            "Questions similar to: Kohinoor\n",
            "0 Question: 3 with score 0.05231352150440216\n",
            "1 Question: 2 with score 0.01187150552868843\n",
            "2 Question: 1 with score 0.0\n",
            "3 Question: 0 with score 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtZuKF-Y3kkB"
      },
      "source": [
        "# Models\n",
        "\n",
        "You may be wondering, \"When are we going to start building models?\" And, the answer is NOW! Finally the time has come to build our baseline model, and then we'll work towards improving it. \n",
        "\n",
        "\n",
        "**NOTE**: We will be using the sample dataset since BERT is really slow and processing the full dataset will take a lot of time. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFesUhmewgGY"
      },
      "source": [
        "### Model 1: Averaging Word Vectors --- TO BE COMPLETED\n",
        "##### <font color='red'>Expected recall@10: ~20%, MRR: ~0.07</font>\n",
        "\n",
        "Complete the `vectorize` function using Spacy provided word embeddings. This is something we've done twice already :) \n",
        "\n",
        "Implementation:\n",
        "\n",
        "1. Tokenize each sentence and get wordVectors for each token in the sentence using Spacy \n",
        "2. Sentence vector is the mean of word vectors of each token\n",
        "3. Stack the sentence vectors into a numpy array using np.stack"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ahi3pH_Ce6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df93fc2b-2631-4057-fab7-1fe423c8bcca"
      },
      "source": [
        "class SpacyVectorizer:\n",
        "  def __init__(self, sentence_vector_dim):\n",
        "    self.sentence_vector_dim = sentence_vector_dim\n",
        "\n",
        "  def vectorize(self, sentences):\n",
        "    \"\"\"Return sentence vectors for the batch of sentences. \n",
        "\n",
        "    1. Tokenize each sentence and create vectors for each token in the sentence\n",
        "    2. Sentence vector is the mean of word vectors of each token\n",
        "    3. Stack the sentence vectors into a numpy array using np.stack\n",
        "    \"\"\"\n",
        "    vectors = []\n",
        "    for sentence in sentences:\n",
        "\n",
        "      ### TO BE COMPLETED ###\n",
        "      spacy_doc = loaded_spacy_model.make_doc(sentence)\n",
        "      word_vector = [token.vector for token in spacy_doc]\n",
        "      sentence_tokens = list([token.text for token in spacy_doc])\n",
        "      sentence_vector = np.mean(np.array(word_vector), axis=0)\n",
        "      ### TO BE COMPLETED ###\n",
        "\n",
        "      vectors.append(sentence_vector)\n",
        "    return np.stack(vectors)\n",
        "\n",
        "\n",
        "spacyIndex = FaissIndexer(sample_dataset,\n",
        "                  question_map,\n",
        "                  sample_eval_dataset,\n",
        "                  batch_size=1024, \n",
        "                  sentence_vector_dim=300, \n",
        "                  vectorizer=SpacyVectorizer(300))\n",
        "\n",
        "spacyIndex.train_and_evaluate(question_example = \"how can i invest in stock market in india?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Indexing ----\n",
            "Start indexing!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [00:02<00:00,  4.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done indexing!\n",
            "\n",
            "---- Search ----\n",
            "Questions similar to: how can i invest in stock market in india?\n",
            "0 Question: 3015 with score 13.855964660644531\n",
            "1 Question: 2559 with score 13.758445739746094\n",
            "2 Question: 1547 with score 13.611780166625977\n",
            "3 Question: 9803 with score 13.450056076049805\n",
            "4 Question: 8533 with score 13.433771133422852\n",
            "5 Question: 4414 with score 13.401880264282227\n",
            "6 Question: 5510 with score 13.392532348632812\n",
            "7 Question: 6928 with score 13.384781837463379\n",
            "8 Question: 9549 with score 13.383279800415039\n",
            "9 Question: 8036 with score 13.366727828979492\n",
            "\n",
            "---- Evaluation ----\n",
            "[(6816, 6817), (7585, 7586), (1604, 1605), (8534, 8535), (4354, 4355), (1316, 1317), (9437, 2388), (3748, 9587), (8158, 8159), (2407, 2408), (839, 840), (1304, 1305), (1919, 6119), (7918, 2438), (8454, 8455), (3793, 9899), (9855, 4191), (7132, 7133), (9455, 9456), (3783, 3784), (30, 1100), (6473, 6474), (8186, 8187), (5911, 2024), (6613, 6069), (690, 6063), (6991, 5516), (6048, 6049), (8510, 8511), (2437, 9006), (7386, 7387), (8362, 8363), (1085, 1086), (5378, 5379), (8039, 8040), (2489, 2490), (5432, 1594), (733, 734), (4122, 4123), (1930, 8974), (9171, 9898), (6377, 6378), (8381, 8382), (9005, 8884), (1779, 3955), (134, 135), (9654, 9655), (7444, 4506), (1285, 6748), (9005, 4050), (1884, 7799), (1928, 1929), (398, 1778), (2853, 7391), (9006, 4051), (6437, 56), (272, 273), (8001, 8002), (9758, 9759), (9703, 5214), (9595, 4753), (6220, 8341), (9673, 9674), (4474, 9829), (4715, 4716), (1976, 6379), (4360, 4361), (3749, 5717), (6271, 6272), (876, 1809), (1374, 4367), (5635, 7525), (9003, 918), (350, 351), (3748, 5717), (8460, 7841), (4002, 4003), (7218, 7219), (4449, 4450), (9457, 9458), (8621, 8622), (2795, 2796), (3612, 3613), (9872, 1977), (2903, 2904), (3072, 4210), (4752, 9596), (4017, 2919), (4445, 1933), (7323, 7765), (8476, 8477), (4378, 3876), (9461, 9462), (5449, 4250), (2994, 2995), (4422, 4423), (1541, 2932), (6318, 1193), (2873, 2874), (2361, 2362), (1824, 1825), (6992, 9739), (2655, 7059), (876, 4366), (8125, 8126), (4410, 4411), (8341, 8342), (3749, 9587), (2655, 3061), (3686, 3687), (6748, 1286), (3482, 3483), (911, 912), (5649, 5650), (2815, 9929), (7831, 7832), (2040, 2041), (144, 2985), (8553, 5790), (642, 4264), (1932, 7917), (1674, 1675), (8301, 8302), (8452, 8453), (2210, 2211), (4752, 4753), (1309, 5297), (5450, 3924), (1181, 1182), (9738, 5517), (569, 2574), (4752, 4210), (1526, 1527), (777, 778), (8461, 6748), (7833, 8568), (8918, 8919), (1990, 1991), (9244, 9245), (965, 5882), (7681, 2681), (3120, 2920), (6759, 5043), (8739, 8740), (7839, 7840), (3999, 1032), (4182, 4183), (8979, 8980), (3999, 5246), (6098, 6099), (3794, 9898), (6491, 6492), (4379, 3876), (4017, 7529), (9276, 9277), (4378, 7332), (398, 399), (9001, 1811), (5357, 3595), (1285, 3938), (2854, 8013), (6800, 145), (7947, 8475), (5215, 5216), (1806, 1807), (9299, 9300), (8884, 6748), (8460, 2322), (8460, 2321), (5741, 7251), (1187, 1404), (3767, 6062), (6798, 4414), (2059, 2060), (5901, 1595), (4323, 3775), (7860, 7341), (2508, 4367), (4547, 4548), (1884, 1885), (9473, 1563), (3564, 3565), (1932, 4051), (6798, 7800), (4626, 6891), (9595, 9596), (7294, 7295), (9388, 9389), (9966, 9967), (3766, 6063), (9587, 7059), (8036, 6799), (8036, 7800), (2071, 2072), (8207, 8208), (9554, 9555), (1201, 3790), (875, 4038), (6355, 6356), (7391, 2854), (3595, 7445), (2787, 2788), (9924, 9925), (6505, 6506), (8829, 8830), (2573, 570), (6955, 6956), (8676, 8677), (5774, 5775), (7947, 8474), (9510, 9511), (9220, 9221), (4263, 642), (5165, 7165), (3336, 3337), (7371, 7372), (7993, 7994), (3718, 3719), (7624, 7625), (1541, 2933), (7524, 9026), (9380, 9381), (7506, 7507), (4211, 4212), (36, 6550), (30, 6936), (6275, 6276), (6678, 6679), (2437, 6748), (547, 548), (3764, 3765), (9500, 9501), (9015, 9016), (6366, 3574), (4733, 4378), (9702, 1840), (7799, 4892), (7115, 8873), (5166, 5517), (803, 804), (8133, 8134), (4305, 4306), (2891, 6311), (2946, 2947), (172, 173), (2655, 7058), (2928, 5882), (2473, 9724), (3505, 5907), (398, 2605), (918, 9004), (6436, 6099), (8701, 8702), (6864, 6865), (9834, 5729), (4505, 4506), (7524, 9419), (3889, 3890), (8039, 1771), (4100, 4101), (8695, 8696), (3748, 7058), (7015, 3594), (5040, 5041), (7791, 7792), (7606, 7607), (2891, 6273), (1606, 1607), (2891, 875), (1107, 1108), (5143, 9675), (1077, 1078), (1886, 1887), (1061, 5717), (1061, 3060), (9005, 8460), (875, 1346), (6800, 144), (5245, 1032), (6170, 7800), (6798, 4415), (8717, 8718), (3260, 7167), (3149, 3150), (9005, 2437), (6394, 6395), (8920, 8921), (1453, 9666), (5093, 5094), (9861, 9862), (4517, 4518), (8255, 8256), (2041, 9227), (170, 171), (2437, 1932), (6896, 6897), (9716, 9717), (4139, 3297), (5166, 7165), (5277, 5278), (6898, 6899), (2579, 5745), (270, 271), (1742, 1743), (1576, 1577), (2863, 2864), (5658, 5659), (4974, 4975), (9131, 9132), (525, 6480), (6436, 6437), (4990, 4991), (5436, 5437), (1356, 1357), (4903, 4904), (539, 540), (7752, 7753), (2891, 2674), (3123, 3124), (1099, 6936), (5332, 5333), (8065, 5722), (1840, 5214), (3173, 3174), (1885, 8036), (2265, 7187), (882, 1893), (1778, 2606), (1666, 1667), (5040, 37), (4905, 4906), (5225, 620), (8260, 1272), (4263, 4264), (5453, 5454), (5666, 5667), (6602, 6603), (3748, 3061), (9530, 9531), (2420, 1201), (5662, 2674), (6798, 6799), (8065, 545), (854, 6193), (5962, 5963), (8884, 3937), (8460, 1286), (9442, 500), (8587, 8588), (4250, 6274), (5516, 5517), (1439, 1941), (2369, 2370), (8576, 8577), (2928, 2929), (9592, 3667), (8206, 5095), (2473, 2474), (9753, 398), (979, 980), (2775, 2776), (955, 956), (5854, 6805), (9001, 9002), (6437, 4414), (3722, 3723), (6727, 6728), (6550, 2373), (6993, 6994), (7829, 7830), (5374, 5375), (1011, 1012), (6103, 7338), (1840, 488), (2437, 4050), (4992, 4993), (6891, 1309), (8460, 2984), (7528, 7753), (2143, 2144), (8241, 8242), (3732, 3733), (1900, 1901), (116, 3874), (597, 1447), (2299, 2300), (1185, 1186), (4537, 4538), (660, 661), (6551, 4407), (5119, 5120), (9519, 9703), (1062, 3060), (875, 6311), (9003, 917), (8243, 8244), (2825, 2826), (7630, 8996), (2597, 2598), (5165, 9738), (8811, 8812), (5575, 9355), (8799, 4366), (8607, 8608), (8884, 2437), (1748, 7752), (1119, 7680), (525, 6479), (4368, 4369), (58, 59), (5040, 4406), (1374, 2508), (4323, 3776), (965, 966), (2605, 1778), (4493, 4494), (1976, 2566), (4138, 3296), (4350, 7800), (1125, 1126), (7740, 7741), (2891, 4367), (4627, 5297), (2208, 2209), (5056, 5057), (1898, 1899), (7136, 7137), (2660, 2661), (1732, 1733), (1037, 7833), (7377, 592), (1802, 1803), (7524, 5636), (545, 8066), (2919, 7529), (6341, 6342), (7242, 7243), (6098, 8153), (8889, 8890), (2655, 5717), (2711, 5358), (9832, 9833), (6365, 3857), (5296, 1309), (6273, 875), (7390, 2853), (7528, 7752), (4036, 4350), (3324, 4476), (8765, 8766), (5893, 5894), (4610, 4611), (4445, 4446), (4868, 4869), (3945, 9595), (7917, 145), (7630, 7631), (9923, 8886), (882, 9666), (3829, 7310), (4483, 4484), (1748, 4017), (1201, 1202), (2531, 2532), (1346, 6312), (158, 159), (3373, 3574), (8401, 8402), (3958, 3959), (36, 1357), (5766, 5767), (5625, 5626), (3046, 3047), (2560, 4415), (9305, 9306), (3380, 3381), (5717, 3061), (9826, 4043), (1316, 3807), (7841, 144), (9137, 1397), (2811, 2812), (9826, 9171), (8065, 8066), (787, 788), (1308, 5297), (2558, 4506), (9188, 6576), (2841, 1527), (9566, 9567), (3766, 3767), (7524, 7525), (1780, 1781), (2936, 2937), (3749, 3060), (8831, 8832), (5433, 1594), (6424, 6425), (2321, 2984), (6437, 7799), (6551, 37), (7681, 2680), (9021, 9022), (7164, 5517), (6436, 1885), (5788, 5789), (9005, 4445), (1932, 1933), (4754, 4755), (6437, 2560), (6613, 5907), (5506, 5507), (5996, 5997), (9532, 9533), (1771, 6069), (2783, 2784), (3789, 2419), (144, 6748), (6437, 6799), (9661, 6480), (8884, 2321), (2441, 2442), (336, 337), (2816, 9929), (2419, 8828), (8800, 4366), (2079, 2080), (2453, 2454), (8022, 8023), (9170, 3794), (6590, 6591), (4273, 4274), (1374, 2507), (2891, 6274), (7528, 4017), (7750, 6078), (4267, 4268), (1906, 1907), (2655, 9587), (9449, 9450), (581, 582), (7363, 7364), (6586, 6587), (1662, 1663), (6608, 6609), (3998, 1032), (8502, 8503), (2263, 6748), (6471, 6472), (6108, 6109), (2437, 8461), (3846, 3847), (8067, 8068), (9859, 9860), (8719, 8720), (5966, 5967), (8114, 5312), (1574, 1575), (1099, 31), (5166, 9738), (7841, 2321), (5798, 5799), (5296, 4627), (9029, 9030), (5988, 5989), (6063, 691), (7959, 9473), (4950, 6551), (2680, 1120), (9036, 9899), (9409, 9410), (4250, 4367), (3915, 3916), (4901, 4902), (8039, 6612), (386, 387), (8153, 2560), (9352, 3666), (56, 6799), (7236, 7237), (9518, 9519), (919, 920), (7799, 2560), (7363, 5307), (9826, 9899), (7918, 2984), (9595, 3073), (3789, 1201), (4475, 1717), (4783, 4784), (4351, 6799), (917, 9004), (5225, 5226), (3506, 6613), (861, 3132), (597, 1448), (2024, 2025), (7058, 1062), (6554, 6555), (5554, 7975), (4445, 4051), (1139, 1140), (9519, 488), (2629, 2630), (7108, 4470), (9352, 9592), (4170, 4171), (2929, 1717), (2323, 2324), (3795, 3796), (7917, 7918), (4117, 5708), (9855, 4190), (6098, 56), (2322, 4051), (3560, 3561), (3131, 3132), (8885, 9923), (6537, 6538), (9002, 1811), (102, 103), (4070, 8552), (4426, 4427), (4138, 4139), (2259, 2260), (7015, 5714), (4348, 4349), (2266, 7187), (8377, 8378), (1941, 1440), (7445, 4505), (3594, 4506), (2936, 9506), (9002, 8638), (7710, 7711), (4770, 5287), (1932, 2985), (6859, 3767), (6995, 6996), (2363, 4993), (5000, 5001), (7086, 8114), (3458, 3459), (656, 657), (2447, 2448), (2508, 4039), (859, 860), (5166, 5516), (4660, 4661), (6588, 6589), (5745, 2580), (6273, 2674), (4654, 4655), (7108, 4469), (6759, 1170), (7466, 7467), (3266, 3267), (8922, 8923), (6273, 5663), (5736, 5737), (170, 6541), (7256, 7257), (5568, 5569), (2891, 2892), (3824, 3825), (4210, 9596), (4886, 4887), (3789, 3790), (3282, 3283), (6068, 8039), (170, 5312), (9005, 1933), (1771, 5271), (2529, 2530), (4351, 6099), (7524, 5635), (3875, 4378), (8352, 9661), (1932, 4446), (7943, 7944), (3838, 3839), (8884, 1285), (6551, 2373), (9293, 9294), (7528, 2919), (2574, 5866), (6170, 6799), (591, 7377), (1840, 489), (4407, 37), (9486, 9487), (9518, 9703), (5756, 5757), (3505, 5908), (7284, 7285), (5854, 5855), (6436, 7800), (3574, 3575), (9986, 9987), (2321, 6748), (31, 1100), (1828, 2326), (1552, 1553), (1564, 1565), (2674, 6312), (6010, 6011), (486, 487), (5662, 5663), (2263, 2321), (9041, 9042), (9212, 9213), (1892, 1453), (9006, 7917), (8642, 8643), (6928, 6929), (2932, 2933), (5948, 5949), (6541, 5313), (4241, 4242), (9916, 172), (9611, 9612), (2617, 7739), (2527, 2528), (3866, 3867), (1746, 1747), (5635, 4628), (8482, 8483), (1464, 1465), (8884, 2438), (3862, 3863), (9688, 9689), (2674, 1347), (4014, 4015), (2560, 4892), (4036, 1885), (2801, 2802), (7720, 7721), (1347, 6312), (4523, 7832), (8259, 8260), (9138, 9139), (5924, 6001), (5006, 5007), (9115, 9116), (1880, 1881), (9184, 8468), (8599, 8600), (1811, 3477), (6515, 6516), (9482, 9483), (9568, 9569), (801, 802), (9660, 6480), (1187, 1188), (1061, 1213), (1201, 8828), (2297, 2298), (3789, 2420), (4050, 4446), (3998, 3999), (6951, 6952), (3259, 545), (476, 477), (6740, 3472), (1291, 1125), (9724, 2474), (4846, 4847), (1007, 1008), (9005, 2322), (7764, 7324), (4382, 4383), (5893, 7251), (1357, 4407), (5193, 5194), (7540, 7541), (7201, 7202), (9486, 395), (7337, 8254), (8022, 9916), (7949, 7950), (882, 4121), (5688, 5689), (9419, 9420), (7059, 3061), (6859, 6063), (6991, 7164), (7416, 7417), (9919, 9920), (3937, 2321), (5121, 5122), (7323, 7324), (7410, 7411), (1061, 1214), (3794, 9036), (4648, 4649), (9218, 9219), (4132, 4133), (2437, 2321), (4406, 4407), (1884, 4350), (4140, 4141), (6118, 1919), (783, 784), (7168, 7251), (7059, 3060), (9902, 9903), (9826, 9036), (8775, 8776), (7318, 635), (1181, 2579), (8697, 8698), (158, 1177), (1308, 1309), (1918, 1919), (6799, 4415), (7250, 7251), (7327, 7328), (5729, 147), (4414, 4892), (1181, 2580), (4949, 6550), (7001, 7002), (8847, 8848), (3487, 3488), (2823, 2824), (1918, 6119), (8227, 8228), (2419, 3790), (5706, 5707), (6747, 1286), (1300, 1301), (370, 8366), (7991, 7992), (9703, 489), (2938, 2939), (1810, 3476), (1940, 1439), (4043, 9899), (4752, 3945), (2985, 2438), (9170, 9036), (3388, 3389), (569, 2573), (3543, 5448), (2915, 2916), (1308, 6891), (3084, 3085), (9376, 9377), (4628, 9420), (862, 3132), (3775, 3776), (7544, 7545), (254, 8031), (4036, 7800), (875, 876), (7799, 56), (4666, 4667), (6028, 9430), (7390, 7391), (9025, 4629), (2674, 4366), (8100, 8101), (8971, 8972), (4016, 2919), (7987, 7988), (6068, 5271), (9528, 9529), (1748, 2919), (1806, 5009), (8946, 8947), (876, 6312), (5913, 3297), (9632, 9633), (8411, 8412), (9170, 9898), (9341, 8890), (3155, 3156), (6273, 1346), (7596, 7597), (8638, 3477), (8977, 8978), (5899, 5900), (1884, 6170), (3875, 3876), (6870, 6871), (1031, 5245), (1062, 5717), (6612, 6613), (2655, 3749), (6541, 171), (9006, 2322), (5141, 5142), (4038, 6312), (5050, 5729), (876, 4367), (7854, 7855), (316, 317), (4811, 4812), (1447, 598), (7841, 2984), (4249, 1346), (8100, 1693), (6230, 6231), (4297, 4298), (1285, 2322), (8884, 8461), (8723, 8724), (250, 251), (2984, 6748), (9002, 1810), (3652, 3653), (1540, 2933), (7032, 7033), (1857, 8974), (3962, 3963), (3348, 3349), (5722, 5723), (5513, 145), (6938, 6939), (1840, 9703), (8456, 8457), (5099, 5100), (8075, 8076), (2220, 1091), (918, 7002), (4626, 5297), (3259, 5723), (6242, 6243), (1541, 7550), (5496, 5497), (5901, 8118), (925, 926), (7087, 6541), (875, 6312), (2437, 3937), (1884, 4351), (9964, 9965), (5357, 5358), (2537, 2538), (5558, 5559), (4445, 4050), (9564, 9565), (3320, 3321), (6448, 6449), (1111, 1112), (9354, 5575), (4733, 4734), (7904, 7890), (537, 538), (2639, 2640), (4000, 4001), (3875, 7331), (3506, 6612), (4202, 4203), (1063, 1064), (8729, 2209), (346, 347), (4524, 7831), (3941, 3942), (3768, 3769), (2558, 4505), (9702, 9519), (561, 562), (2208, 5608), (4392, 4393), (7905, 7906), (9244, 7324), (9916, 8023), (5729, 8243), (4445, 7918), (9753, 3955), (5433, 8118), (4729, 4730), (3391, 4449), (3550, 3551), (4701, 4702), (2839, 2840), (585, 586), (2321, 2985), (3408, 3409), (8891, 8892), (2919, 7753), (6436, 4350), (1896, 1897), (1346, 4366), (7390, 8866), (1286, 3938), (6420, 8468), (5040, 4407), (5145, 5146), (9607, 9608), (1285, 1286), (8468, 8469), (1237, 1238), (6802, 6803), (4051, 2438), (3773, 59), (1624, 1625), (9678, 9679), (1421, 1422)]\n",
            "\n",
            "Recall@10:\t\t20.80%\n",
            "Mean Reciprocal Rank:\t0.07042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHoRuwCOwhiH"
      },
      "source": [
        "### Model 2: BERT Embeddings --- TO BE COMPLETED\n",
        "##### <font color='red'>Expected recall@10: ~48%, MRR: ~0.19</font>\n",
        "\n",
        "Compute the sentence embeddings using the BERT model and complete the `vectorize` function. Feel free to reference any documentation from https://huggingface.co/. \n",
        "\n",
        "\n",
        "Implementation:\n",
        "\n",
        "1. Tokenize batch of sentences using `self.tokenizer`\n",
        "2. Pipe the inputs through the BERT model to create the output logits\n",
        "3. Normalize the batch output\n",
        "\n",
        "**NOTE: This model is really slow and will take about 20 mins to run**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAWOt3cTC9Ig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c3f9a2b-eda1-4d94-c488-ba2d2a0f0c79"
      },
      "source": [
        "class BertVectorizer:\n",
        "  def __init__(self):\n",
        "    self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "    self.model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "  def vectorize(self, sentences):\n",
        "    \"\"\"Return sentence vectors for the batch of sentences. \n",
        "\n",
        "    1. Tokenize batch of sentences using `self.tokenizer`\n",
        "    2. Pipe the inputs through the BERT model to create the output logits\n",
        "    3. Normalize the batch output\n",
        "    \"\"\"\n",
        "    \n",
        "    ### TO BE COMPLETED ###\n",
        "    inputs = self.tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "    with torch.no_grad():\n",
        "      outputs = self.model(**inputs)\n",
        "\n",
        "    model_output = outputs.last_hidden_state\n",
        "\n",
        "    ### TO BE COMPLETED ###\n",
        "\n",
        "    return F.normalize(torch.mean(model_output, dim=1), dim=1).detach().numpy()\n",
        "\n",
        "\n",
        "bertIndex = FaissIndexer(sample_dataset,\n",
        "                  question_map,\n",
        "                  sample_eval_dataset,\n",
        "                  batch_size=32, \n",
        "                  sentence_vector_dim=768, \n",
        "                  vectorizer=BertVectorizer())\n",
        "\n",
        "bertIndex.train_and_evaluate(question_example = \"how can i invest in stock market in india?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Indexing ----\n",
            "Start indexing!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [12:09<00:00,  2.33s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done indexing!\n",
            "\n",
            "---- Search ----\n",
            "Questions similar to: how can i invest in stock market in india?\n",
            "0 Question: 1744 with score 0.8770731091499329\n",
            "1 Question: 0 with score 0.874489426612854\n",
            "2 Question: 5070 with score 0.8723899126052856\n",
            "3 Question: 589 with score 0.863616406917572\n",
            "4 Question: 9753 with score 0.8614913821220398\n",
            "5 Question: 875 with score 0.8532259464263916\n",
            "6 Question: 6101 with score 0.8521274328231812\n",
            "7 Question: 9443 with score 0.8468542098999023\n",
            "8 Question: 4414 with score 0.8458528518676758\n",
            "9 Question: 2926 with score 0.8440940380096436\n",
            "\n",
            "---- Evaluation ----\n",
            "[(3592, 3593), (5020, 5021), (1960, 5745), (2879, 2880), (6938, 6939), (6098, 8036), (1854, 1855), (7390, 4099), (7323, 7324), (9855, 9856), (8775, 8776), (8065, 5722), (2823, 2824), (1308, 4627), (2656, 2657), (1157, 1158), (9005, 3937), (5121, 8352), (1618, 1619), (3748, 5717), (7294, 598), (5934, 5935), (472, 473), (7905, 7906), (2511, 2512), (3374, 3375), (7258, 7259), (4753, 9596), (8552, 8553), (2427, 2428), (8837, 8838), (4493, 4494), (3554, 3555), (9834, 147), (5095, 5096), (5121, 9660), (134, 135), (1201, 3790), (8676, 7201), (5214, 489), (7919, 7920), (4695, 4696), (1892, 882), (9619, 9620), (660, 661), (9803, 9804), (8991, 8992), (4305, 4306), (7524, 9419), (7873, 7874), (8460, 144), (5556, 5557), (9723, 9724), (2605, 3955), (1670, 9945), (6977, 9348), (6273, 6311), (2387, 9437), (6312, 2508), (3505, 1771), (106, 107), (3612, 7334), (7349, 7350), (9753, 3955), (4138, 5913), (1472, 1473), (6859, 6063), (569, 3486), (5666, 5667), (5221, 5222), (6862, 6863), (170, 5312), (889, 890), (8073, 8074), (5893, 7251), (2791, 2792), (524, 8352), (5372, 5373), (7748, 7749), (184, 185), (2143, 2144), (1346, 6312), (7841, 2321), (2891, 2508), (3795, 3796), (6436, 1885), (5876, 5271), (4350, 6170), (1201, 1202), (7201, 7202), (6947, 6948), (1690, 1691), (3373, 3575), (9930, 9931), (7076, 7077), (8100, 8101), (1348, 1349), (2220, 1091), (3422, 3423), (4037, 4351), (7294, 7295), (7310, 7311), (875, 4038), (6671, 6306), (6170, 6799), (4221, 4222), (3543, 4366), (1632, 1633), (6798, 7800), (4297, 4298), (1828, 1829), (5290, 5291), (8119, 8120), (6664, 6665), (4602, 4603), (2437, 4445), (4662, 4663), (3945, 9595), (5729, 8244), (2373, 37), (440, 441), (6098, 6437), (6402, 6403), (7318, 635), (918, 9004), (7312, 7313), (4198, 4199), (2655, 3749), (2710, 2711), (1808, 6000), (6202, 6203), (1464, 1465), (7528, 7529), (2501, 2680), (2221, 2222), (1372, 8237), (887, 888), (9004, 7002), (4120, 1893), (9244, 9245), (4117, 5709), (7438, 7439), (2558, 2710), (1237, 1238), (3937, 3938), (1213, 9587), (7178, 9751), (4038, 1374), (5357, 7445), (4437, 4438), (3939, 3940), (7630, 7631), (690, 691), (4628, 9420), (1061, 7058), (7854, 6928), (6252, 6253), (4547, 4548), (6366, 3373), (6062, 6063), (6436, 6799), (6780, 6781), (6098, 6099), (2674, 4366), (2265, 2266), (168, 169), (6922, 6923), (8333, 8334), (5728, 9834), (5091, 5092), (4273, 4274), (7022, 7023), (7899, 7900), (7742, 7743), (9025, 4629), (1286, 3938), (1308, 5297), (569, 570), (9627, 6419), (5121, 9661), (9374, 9375), (3954, 3955), (2024, 9848), (7901, 574), (2325, 2326), (522, 523), (9005, 2437), (7799, 8036), (2373, 4407), (3897, 3898), (5741, 7168), (1061, 7059), (9696, 2816), (2674, 2508), (6800, 144), (5143, 5144), (2375, 2376), (9311, 9312), (5901, 5433), (8638, 8639), (2507, 4039), (1346, 5449), (1932, 4051), (2321, 2985), (7468, 7469), (3072, 9596), (6804, 6805), (6612, 5908), (4830, 4831), (458, 459), (641, 6720), (7740, 7741), (1257, 1258), (3233, 3234), (4350, 6099), (9170, 3794), (5990, 5991), (1832, 1833), (1892, 1893), (5265, 5266), (6436, 4036), (8800, 4366), (2291, 2292), (7567, 7568), (8039, 1771), (1478, 1479), (6318, 1193), (6580, 6581), (1749, 7529), (8801, 8802), (4725, 4726), (8658, 8659), (7650, 7651), (8259, 9282), (3789, 1201), (651, 107), (2419, 3790), (24, 25), (5306, 5307), (1439, 1440), (6896, 6897), (8190, 8191), (1202, 3790), (1249, 1250), (1312, 1313), (6613, 6069), (7841, 6748), (9242, 6890), (3992, 3993), (442, 443), (5213, 9703), (8767, 8768), (5621, 5622), (7332, 3876), (9347, 1815), (8827, 1202), (8251, 8252), (5513, 144), (8576, 8577), (8411, 8412), (6992, 5517), (7168, 7251), (6103, 7338), (3394, 3395), (2985, 2438), (8118, 1595), (9718, 6423), (1748, 2919), (6748, 1286), (7706, 3594), (6222, 6223), (8039, 5907), (3388, 3389), (7087, 5312), (9016, 4478), (1931, 1857), (2558, 7444), (4882, 4883), (1748, 3120), (7418, 7419), (7947, 8540), (5225, 620), (2629, 2630), (4445, 7918), (692, 693), (6072, 6073), (2453, 2454), (8512, 3790), (3875, 4378), (319, 8238), (4036, 1884), (5165, 5517), (2574, 5866), (7203, 7204), (9826, 9036), (4876, 4877), (4711, 4712), (6859, 690), (7058, 3749), (7528, 7752), (4344, 4345), (6550, 4406), (6078, 6079), (8153, 4415), (9435, 9436), (3941, 3942), (8747, 8748), (3328, 4737), (2508, 4366), (2738, 1070), (5740, 5893), (4139, 3297), (1099, 31), (7084, 7085), (5568, 5569), (6759, 1169), (2467, 2468), (965, 5881), (8785, 8786), (2558, 3595), (1346, 4366), (9766, 9767), (9834, 5051), (5902, 1595), (1062, 1214), (1961, 5745), (4896, 4897), (3560, 3561), (2508, 6274), (2595, 2596), (2473, 2474), (6847, 6848), (9011, 9012), (1892, 9666), (488, 489), (8474, 8541), (7799, 8153), (876, 6312), (3889, 3890), (9587, 1214), (1448, 7295), (537, 538), (3112, 3113), (9005, 6748), (6230, 6231), (9170, 9036), (5873, 5874), (4445, 4446), (1910, 1911), (8897, 8898), (3251, 3252), (7861, 7862), (6379, 9873), (4949, 4407), (3064, 3065), (96, 97), (704, 133), (3505, 6612), (9001, 3476), (2040, 9227), (5040, 6551), (5099, 5100), (492, 493), (2321, 2984), (1187, 1404), (3329, 4737), (1884, 2560), (4264, 7310), (7420, 7421), (8857, 8858), (1038, 854), (5478, 5479), (5645, 5646), (6759, 5043), (3749, 3060), (7177, 9752), (7495, 184), (4627, 5297), (8755, 8756), (4037, 4415), (545, 546), (4116, 5709), (7386, 7387), (6273, 4366), (3120, 2920), (8385, 1541), (6997, 6998), (6305, 6306), (4017, 2920), (8958, 1008), (4811, 4812), (5744, 5745), (3816, 3817), (5554, 5555), (5449, 6274), (5056, 5057), (8578, 8579), (5663, 6274), (694, 695), (9429, 9430), (5524, 5525), (7943, 7944), (7444, 4505), (4099, 2853), (6816, 6817), (2371, 2372), (2507, 4367), (8436, 8437), (9037, 9038), (2095, 2096), (4817, 4264), (7242, 7243), (2419, 8828), (7108, 4470), (7165, 5517), (5508, 5509), (645, 646), (597, 1447), (226, 227), (4412, 4413), (524, 6480), (318, 319), (7020, 7021), (2660, 2661), (7681, 2681), (398, 1778), (1061, 1062), (3748, 9587), (1828, 2326), (4774, 4122), (352, 353), (8811, 8436), (7962, 7963), (7575, 7576), (8574, 8575), (116, 117), (9510, 9511), (7829, 7830), (3895, 3896), (4036, 7800), (6275, 6276), (1346, 5448), (9826, 9898), (9417, 9418), (2531, 2532), (7332, 4379), (5902, 5433), (597, 598), (7995, 7996), (5051, 147), (6098, 4892), (6437, 56), (4453, 4454), (5532, 5533), (3543, 4250), (1309, 5297), (9847, 2024), (597, 7295), (8460, 3938), (5729, 8243), (3476, 8638), (4140, 1028), (8638, 1811), (2307, 2308), (5436, 5437), (8811, 8437), (1893, 4121), (1749, 4017), (3312, 3313), (4474, 4475), (2560, 7800), (5006, 5007), (9688, 9689), (6220, 6221), (6951, 6952), (4524, 7831), (3308, 3309), (1309, 4627), (6026, 6027), (3501, 3502), (1347, 6274), (7462, 7463), (7327, 7328), (7833, 7834), (8466, 8467), (124, 125), (4544, 7200), (116, 6952), (7841, 144), (5740, 5741), (9650, 9651), (6864, 6865), (2817, 2818), (3793, 9898), (3937, 2985), (4856, 4857), (4120, 4121), (9855, 4190), (3348, 5854), (6891, 5297), (2985, 6748), (358, 359), (5225, 5226), (5449, 4250), (5135, 5136), (1346, 6274), (2419, 1202), (2747, 2748), (7377, 592), (3595, 4506), (58, 3773), (875, 1346), (5348, 5349), (9035, 9898), (172, 173), (6080, 6081), (5213, 9702), (6800, 3938), (8065, 8066), (40, 41), (2825, 2826), (3793, 3794), (8159, 807), (8460, 2984), (882, 4121), (8995, 7631), (7495, 185), (966, 2929), (9834, 5729), (7375, 7376), (5954, 5955), (6674, 6675), (4752, 9596), (3260, 8066), (6102, 6103), (3259, 3260), (2437, 3937), (4078, 4079), (5557, 2995), (10, 11), (56, 4892), (8871, 8872), (5062, 5063), (6221, 8342), (4043, 3794), (1409, 1410), (6739, 6740), (1119, 1120), (8022, 9916), (3594, 8684), (171, 8114), (1073, 1074), (1182, 2580), (5378, 5379), (4919, 4920), (9162, 5979), (6818, 6819), (3856, 3857), (676, 677), (1800, 1801), (5089, 5090), (9115, 9116), (3948, 3949), (8028, 8029), (1562, 1563), (8981, 8982), (7758, 7759), (4446, 145), (6312, 4366), (7833, 6193), (4892, 4415), (2801, 2802), (1541, 2932), (1748, 1749), (2420, 8827), (4351, 7800), (3789, 2420), (2839, 2840), (9702, 5214), (1556, 1557), (2407, 2408), (2680, 1120), (5038, 5039), (510, 511), (6991, 7164), (9473, 1563), (5911, 9848), (9283, 9284), (1031, 1032), (7885, 7886), (3572, 3573), (3748, 1062), (3923, 3924), (9764, 9765), (2655, 3060), (8120, 3780), (9025, 9420), (9587, 1062), (4186, 4187), (4489, 4490), (2411, 2412), (9630, 9631), (6491, 6492), (5432, 1594), (525, 9661), (4241, 8659), (4249, 1347), (2501, 7681), (6822, 6823), (6718, 6719), (6048, 6049), (8475, 7948), (875, 6274), (1269, 1270), (1271, 9282), (4822, 4823), (9666, 4121), (4495, 4496), (1448, 598), (6166, 6167), (9029, 9030), (3199, 3200), (1892, 881), (1954, 1955), (4764, 4765), (7585, 7586), (1037, 6193), (8685, 8686), (8461, 6748), (7551, 7552), (4241, 8658), (7323, 9244), (1885, 6099), (7059, 3061), (1564, 1565), (4445, 2985), (8153, 7800), (975, 976), (979, 980), (2438, 1286), (2002, 2003), (2617, 7739), (6437, 8036), (1103, 1104), (915, 916), (1650, 1651), (3803, 3804), (3476, 1811), (5856, 5857), (6273, 2674), (3945, 3072), (4474, 9829), (7486, 7487), (346, 347), (8427, 4017), (6989, 6990), (6140, 6141), (6118, 1919), (5913, 3297), (4445, 7841), (380, 381), (7445, 4505), (7400, 7401), (1840, 9519), (642, 6720), (2501, 7680), (641, 4263), (7917, 1933), (7791, 7792), (4036, 8036), (6503, 6504), (2655, 1062), (8823, 8824), (5336, 5337), (5165, 7165), (1113, 1114), (7183, 7184), (2816, 9929), (1023, 1024), (170, 171), (4150, 4151), (8827, 1201), (7974, 7975), (3945, 9596), (839, 840), (1541, 7550), (6394, 6395), (8153, 4414), (7710, 7711), (1806, 1807), (5732, 5733), (4543, 4544), (1574, 1575), (3999, 5245), (8260, 1272), (6991, 5166), (2558, 5358), (1375, 5448), (6678, 8254), (130, 131), (4813, 4814), (9908, 9909), (573, 5455), (6421, 8469), (2984, 2438), (5159, 5160), (9859, 9860), (3828, 4264), (5122, 6480), (2619, 2620), (2473, 9724), (8355, 8356), (5312, 5313), (876, 2507), (9906, 9907), (795, 796), (9212, 9213), (9826, 4043), (2560, 4415), (1201, 8828), (2210, 2211), (2387, 2388), (4414, 4415), (2333, 2334), (791, 792), (2891, 5449), (3937, 2984), (1095, 1096), (9747, 9748), (5788, 5789), (6670, 6671), (875, 4249), (3789, 3790), (8386, 2933), (3632, 3633), (1998, 1999), (2891, 875), (6951, 117), (7799, 6799), (9678, 9679), (6436, 4414), (1031, 5246), (7494, 184), (7993, 7994), (9738, 9739), (5307, 7364), (6926, 6927), (4950, 4407), (240, 241), (158, 1178), (6420, 8469), (8022, 172), (6799, 4415), (4523, 7832), (9003, 7001), (1838, 1839), (6574, 6575), (7658, 7659), (1033, 1034), (9243, 6890), (418, 419), (8227, 8228), (9077, 9078), (3543, 4039), (1165, 1166), (1862, 8357), (7918, 2438), (7363, 5307), (733, 734), (7015, 4506), (1061, 3749), (6551, 2373), (8884, 2437), (4543, 7200), (9872, 2566), (7815, 7816), (9113, 9114), (9826, 9170), (3452, 3453), (9928, 9929), (4032, 4033), (8223, 8224), (7086, 5313), (2373, 4406), (642, 7310), (5448, 6312), (5662, 6274), (6365, 3857), (6936, 1100), (3120, 4017), (4463, 4464), (237, 6108), (9021, 9022), (2885, 2886), (6700, 6701), (5717, 3060), (3348, 5855), (3372, 6366), (6479, 5122), (5850, 5851), (5455, 574), (1181, 5744), (6273, 6312), (7394, 7395), (6501, 6502), (3749, 9587), (7841, 2438), (360, 361), (3120, 2919), (2034, 2035), (1356, 2373), (7390, 8013), (2297, 2298), (5340, 5341), (1644, 1645), (3175, 3176), (853, 1038), (4016, 2920), (8352, 6479), (5729, 5051), (911, 912), (9016, 4477), (7382, 7383), (876, 4250), (6473, 6474), (9299, 9300), (5911, 2025), (1285, 2322), (4687, 4688), (7799, 4415), (6798, 6799), (6891, 4627), (8039, 6613), (1807, 5009), (3169, 3170), (6479, 6480), (1590, 1591), (6910, 6911), (4043, 9899), (1181, 2579), (4888, 4889), (5631, 5632), (7087, 5313), (9002, 8639), (1271, 8260), (36, 1356), (6800, 5513), (6608, 6609), (5137, 5138), (144, 7918), (4043, 9898), (4291, 4292), (8532, 8533), (7086, 7087), (4949, 2373), (1918, 1919), (8508, 7311), (4140, 4141), (7528, 4016), (5830, 5831), (3564, 3565), (6479, 4549), (2853, 7391), (8642, 8643), (5875, 5876), (8431, 3393), (5635, 4629), (725, 726), (6541, 8114), (8241, 8242), (6311, 4366), (8621, 8622), (6420, 6421), (9182, 9183), (9753, 1779), (5901, 5432), (3794, 9899), (4263, 4817), (3476, 3477), (7278, 7279), (144, 1932), (6068, 5271), (919, 920), (56, 4415), (9626, 6419), (573, 574), (2558, 4506), (4070, 4071), (9700, 9701), (4626, 4627), (7917, 145), (1628, 1629), (2815, 9696), (9964, 9965), (5875, 5908), (502, 503), (5298, 5299), (3962, 3963), (6612, 6613), (641, 4264), (1067, 1068), (9447, 9448), (4446, 1933), (9924, 9925), (9519, 9703), (3362, 3363), (1754, 1755), (1810, 1811), (1857, 8973), (6505, 6506), (7001, 917), (7390, 7391), (8343, 8344), (1772, 1773), (7854, 7855), (803, 884), (6122, 6123), (4475, 1717), (5051, 8243), (4640, 4641), (524, 5121), (3958, 3959), (3856, 6366), (6991, 5165), (5203, 5204), (5722, 5723), (2674, 1347), (7314, 7315), (4610, 4611), (6666, 6667), (7841, 7918), (1930, 1931), (4016, 4017), (14, 15), (9532, 9533), (1061, 1214), (2789, 2790), (8377, 8378), (8512, 8513), (1037, 853), (4752, 4210), (2437, 2321), (2527, 2528), (9129, 9130), (4174, 4175), (7066, 7067), (6274, 4367), (6727, 6443), (6606, 6607), (8301, 8302), (3915, 3916), (4378, 4379), (9392, 9393), (9394, 9395), (4774, 4775), (9319, 9320), (6412, 6413), (30, 6936), (6993, 6994), (6550, 2373), (2295, 2296), (8884, 1285), (1748, 2920), (9352, 3666), (4056, 4057), (1213, 3060), (1932, 2985), (3748, 3061), (5227, 5228), (539, 540), (1300, 1301), (2042, 2043), (2655, 3061), (3072, 9595), (4351, 1885), (376, 377), (8254, 6679), (1746, 1747), (2676, 2677), (3828, 642), (9006, 1933), (2233, 2234), (1177, 159), (1930, 8974), (1183, 1184), (6170, 4351), (4250, 2508), (9876, 9877), (8231, 8232), (6550, 1356), (1884, 7800), (7821, 7822), (3998, 1032), (7901, 5455), (1885, 7800), (1357, 37), (6436, 1884), (9898, 9899), (5651, 5652), (316, 317)]\n",
            "\n",
            "Recall@10:\t\t48.40%\n",
            "Mean Reciprocal Rank:\t0.18830\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bLdQ4pQwo-m"
      },
      "source": [
        "### Model 3: Sentence Transformer --- TO BE COMPLETED\n",
        "##### <font color='red'>Expected recall@10: ~93%, MRR: ~0.34</font>\n",
        "\n",
        "Compute the sentence embeddings using the Sentence BERT model and complete the `vectorize` function. Feel free to look up documentation on https://www.sbert.net/. \n",
        "\n",
        "Implementation:\n",
        "\n",
        "1. Pipe the input sentences through the Sentence BERT model to create the output logits\n",
        "2. Normalize the batch output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpTt--KFTd3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64916573-ca6a-4e20-8cf9-767b4d65338c"
      },
      "source": [
        "class SentenceBertVectorizer:\n",
        "  def __init__(self):\n",
        "    self.model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "\n",
        "  def vectorize(self, sentences):\n",
        "    \"\"\"Return sentence vectors for the batch of sentences. \n",
        "\n",
        "    1. Pipe the input sentences through the Sentence BERT model to create the output logits\n",
        "    2. Normalize the batch output\n",
        "    \"\"\"\n",
        "\n",
        "    ### TO BE COMPLETED ###\n",
        "    sentence_vectors = self.model.encode(sentences)\n",
        "    ### TO BE COMPLETED ###\n",
        "\n",
        "    return sentence_vectors / np.expand_dims(np.linalg.norm(sentence_vectors, axis=1), axis=1)\n",
        "\n",
        "\n",
        "SBertIndex = FaissIndexer(sample_dataset,\n",
        "                  question_map,\n",
        "                  sample_eval_dataset,\n",
        "                  batch_size=1024, \n",
        "                  sentence_vector_dim=384, \n",
        "                  vectorizer=SentenceBertVectorizer())\n",
        "\n",
        "SBertIndex.train_and_evaluate(question_example = \"how can i invest in stock market in india?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Indexing ----\n",
            "Start indexing!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:07<00:00, 12.71s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done indexing!\n",
            "\n",
            "---- Search ----\n",
            "Questions similar to: how can i invest in stock market in india?\n",
            "0 Question: 0 with score 0.7331767082214355\n",
            "1 Question: 1745 with score 0.6957337856292725\n",
            "2 Question: 3779 with score 0.6243616342544556\n",
            "3 Question: 8147 with score 0.6239824295043945\n",
            "4 Question: 8120 with score 0.6222877502441406\n",
            "5 Question: 1 with score 0.6042821407318115\n",
            "6 Question: 3780 with score 0.6032655239105225\n",
            "7 Question: 8119 with score 0.5846709609031677\n",
            "8 Question: 3015 with score 0.5778072476387024\n",
            "9 Question: 5070 with score 0.5576668381690979\n",
            "\n",
            "---- Evaluation ----\n",
            "[(6042, 6043), (6740, 3472), (9658, 9659), (9005, 4051), (9518, 5214), (6054, 6055), (1346, 1347), (7108, 4469), (2859, 2860), (9339, 9340), (6541, 171), (3762, 3763), (3151, 3152), (7559, 7560), (9016, 4478), (853, 8568), (1892, 1893), (567, 5510), (5143, 9675), (9753, 3954), (2529, 2530), (1374, 4250), (2641, 2642), (6798, 6799), (7042, 7043), (254, 8031), (3992, 3993), (9041, 9042), (2249, 2250), (4628, 7525), (8123, 8124), (2065, 31), (3340, 3341), (7310, 6720), (8607, 8608), (1778, 1779), (9170, 9036), (9739, 7164), (4050, 1932), (7624, 7625), (9834, 147), (3348, 3349), (1449, 1450), (5554, 5555), (1372, 2846), (6798, 8153), (8638, 3477), (4078, 4079), (5538, 5539), (3948, 3949), (9409, 9410), (5790, 5791), (2322, 4051), (2501, 2502), (4640, 4641), (8158, 807), (615, 616), (4446, 1933), (8747, 8748), (8039, 8040), (2319, 2320), (8857, 8858), (8399, 8240), (3856, 3574), (6700, 6701), (4951, 4952), (2823, 2824), (9928, 2816), (6537, 6538), (9003, 7001), (8936, 8937), (3476, 8638), (8765, 8766), (9047, 9048), (1940, 1941), (6170, 4351), (5893, 5741), (5912, 2025), (9619, 9620), (1886, 1887), (9826, 9898), (5486, 5487), (2891, 6274), (3574, 3575), (8966, 8967), (1292, 1293), (6483, 6484), (7331, 3876), (7680, 7681), (6436, 4351), (9184, 9185), (5514, 5515), (5936, 5937), (6305, 6306), (5934, 5935), (250, 251), (3766, 690), (1892, 9666), (1285, 3938), (5496, 5497), (5348, 5349), (7848, 7849), (5432, 5433), (8874, 8875), (7495, 185), (3945, 3073), (4872, 4873), (5786, 5787), (3209, 3210), (400, 635), (3794, 9899), (56, 6099), (7976, 7977), (1103, 9621), (3793, 3794), (569, 2574), (7152, 7153), (3856, 3575), (6436, 4350), (1732, 1733), (1352, 1353), (1486, 1487), (5641, 5642), (6103, 7338), (8553, 4071), (1285, 6748), (2579, 2580), (3818, 3819), (8255, 8256), (7799, 6099), (498, 499), (4346, 4347), (777, 778), (4598, 4599), (1119, 7680), (4263, 7310), (1286, 3938), (4084, 4085), (3259, 545), (6971, 6972), (5924, 6001), (3594, 4505), (124, 125), (3072, 9596), (4903, 4904), (3476, 1811), (5109, 5110), (6437, 7799), (1826, 1827), (9435, 9436), (8461, 1933), (9928, 9929), (6800, 3938), (486, 487), (3364, 3365), (4624, 4625), (725, 726), (440, 441), (56, 4892), (5432, 8118), (1650, 1651), (4138, 3297), (6992, 5166), (7428, 7429), (8697, 8698), (3594, 5357), (8239, 8240), (3875, 3876), (5307, 7364), (2437, 4445), (7833, 6193), (5688, 5689), (4919, 4920), (4036, 1885), (9162, 9163), (4249, 1347), (1099, 1100), (1540, 2932), (4817, 7310), (3766, 6063), (7750, 7751), (3131, 862), (2629, 2630), (5722, 7166), (1976, 9873), (7323, 5671), (4701, 4702), (4483, 4484), (1104, 9621), (58, 3773), (1374, 5448), (6394, 6395), (8065, 3259), (9739, 7165), (8237, 1373), (36, 4950), (7668, 7669), (4036, 7800), (1213, 3061), (4787, 4788), (7108, 7109), (8081, 8082), (5670, 5671), (645, 646), (5449, 4250), (8741, 8742), (9025, 9419), (1038, 8568), (5728, 9834), (9794, 2292), (6798, 4037), (1405, 1406), (9394, 9395), (9944, 9945), (2846, 1373), (4626, 4627), (8385, 8386), (6076, 6077), (9037, 9038), (1748, 7752), (64, 65), (5040, 5041), (857, 858), (569, 570), (882, 1453), (7185, 7186), (5449, 6274), (4138, 5913), (4414, 4892), (4356, 4357), (8100, 8101), (3937, 2322), (7974, 5554), (3179, 3180), (3338, 3339), (8360, 8361), (3779, 3780), (5798, 5799), (2531, 2532), (3766, 3767), (889, 890), (8460, 7918), (641, 6720), (9595, 9596), (9274, 9275), (5635, 4629), (326, 327), (2363, 4993), (5717, 3061), (2565, 9872), (3824, 3825), (1885, 7800), (3632, 3633), (2579, 1182), (5670, 7324), (6579, 499), (2473, 2474), (9738, 7165), (3988, 3989), (8101, 1692), (8544, 8545), (5056, 5057), (875, 876), (2674, 2508), (9376, 9377), (6421, 8469), (36, 1357), (2891, 6312), (6022, 6023), (1285, 1286), (6798, 4415), (7312, 7313), (3473, 2490), (5050, 5729), (6063, 691), (7258, 7259), (432, 433), (3748, 3060), (8884, 2438), (4140, 4141), (9005, 2321), (5722, 7167), (6366, 3373), (9176, 9177), (6437, 2560), (6847, 6848), (9218, 9219), (2716, 2717), (4184, 4185), (6798, 56), (2853, 8013), (2795, 2796), (5901, 8118), (9429, 6029), (7001, 9004), (5911, 2024), (4190, 4191), (9940, 9941), (7496, 7497), (1540, 8386), (6062, 691), (882, 4121), (9692, 9693), (804, 884), (6774, 6775), (2321, 3938), (6436, 4036), (7468, 7469), (7799, 4414), (2042, 2043), (8975, 8976), (4120, 4121), (1163, 1164), (1706, 1707), (4130, 4131), (1453, 9666), (5723, 3260), (3748, 3061), (4905, 4906), (4949, 37), (4263, 4264), (6533, 6534), (5121, 5122), (6273, 4366), (3592, 3593), (3612, 7334), (6437, 6170), (591, 7377), (1918, 6118), (1309, 4627), (6759, 1170), (8377, 8378), (146, 147), (3767, 6063), (6668, 6669), (3803, 3804), (8460, 8884), (7363, 5307), (9011, 9012), (9518, 488), (8809, 8810), (4140, 1028), (4892, 4415), (4978, 4979), (2841, 1526), (5095, 5096), (5166, 9738), (5645, 5646), (5717, 7059), (9738, 5517), (3793, 9899), (2763, 2764), (4358, 4359), (9703, 5214), (9473, 1563), (8672, 8673), (965, 5882), (7341, 7342), (4305, 4306), (7032, 7033), (1800, 1801), (4576, 4577), (1374, 1375), (7318, 636), (4350, 6170), (9352, 3667), (4014, 4015), (4950, 6551), (4116, 4117), (8890, 9342), (4752, 4210), (9449, 9450), (7001, 917), (1771, 6613), (9006, 1933), (520, 521), (5662, 2508), (7706, 3594), (7494, 185), (4733, 3875), (1514, 1515), (7058, 7059), (641, 7310), (5663, 6274), (2034, 2035), (9902, 9903), (9564, 9565), (6664, 6665), (6436, 4892), (8689, 8690), (2674, 6312), (2605, 1778), (4036, 4350), (9892, 9893), (7058, 3749), (396, 397), (9863, 8042), (4578, 4579), (3999, 5245), (8767, 8768), (9005, 8884), (8482, 8483), (9001, 8638), (5568, 5569), (9319, 9320), (2208, 5608), (1107, 1108), (861, 862), (288, 289), (3937, 3938), (3266, 3267), (4352, 4353), (5121, 6480), (7959, 9473), (8460, 2321), (1247, 1248), (9170, 9898), (4264, 7310), (3980, 3981), (6770, 6771), (5424, 5425), (1692, 1693), (7972, 7973), (6028, 6029), (2420, 1201), (3329, 4737), (9001, 1810), (6437, 56), (2420, 8827), (2271, 2272), (7841, 7918), (132, 133), (881, 882), (1372, 8237), (2420, 3790), (4366, 6274), (5902, 5433), (2891, 5449), (853, 854), (4323, 3775), (7524, 5635), (6889, 6890), (8599, 8600), (1291, 1126), (7234, 7235), (8621, 8622), (6068, 6069), (6311, 2508), (881, 4121), (3476, 3477), (2891, 2674), (7318, 635), (2919, 2920), (1562, 1563), (6098, 1884), (1778, 2606), (3478, 3479), (8460, 7841), (8194, 8195), (6069, 5907), (4911, 4912), (2527, 2528), (8430, 8431), (5513, 7841), (6995, 6996), (4204, 4205), (8532, 8533), (3282, 3283), (4351, 7800), (6246, 6247), (40, 41), (4328, 4329), (6305, 6671), (3543, 4366), (549, 550), (5522, 5523), (2579, 5745), (9766, 9767), (5306, 5307), (5518, 5519), (6503, 6504), (9026, 4629), (2605, 2606), (8036, 4415), (6747, 3938), (1291, 1125), (2966, 2967), (1810, 8638), (6436, 6437), (7606, 7607), (8231, 8232), (7250, 7251), (1213, 9587), (6436, 4414), (9170, 9899), (917, 9004), (7860, 319), (4992, 2363), (1372, 1373), (6801, 2984), (4445, 1933), (7462, 7463), (1960, 1961), (3748, 5717), (3937, 4051), (6206, 6207), (31, 6937), (6004, 6005), (1600, 1601), (763, 764), (4628, 4629), (2438, 6748), (4190, 9856), (4198, 4199), (3858, 3859), (6578, 6579), (6420, 6421), (9758, 9759), (6279, 6280), (5556, 5557), (7314, 7315), (3372, 3373), (9006, 4050), (3506, 6068), (7800, 6099), (2560, 4892), (5157, 5158), (3856, 3373), (5357, 7445), (214, 215), (4424, 4425), (5979, 9163), (7770, 7771), (36, 37), (575, 576), (8981, 8982), (1840, 9519), (3073, 4210), (1808, 6000), (8362, 8363), (3768, 3769), (1857, 8974), (4180, 4181), (3749, 9587), (8036, 7800), (4116, 5708), (9661, 5122), (2533, 2534), (2597, 2598), (5050, 5051), (398, 3955), (6436, 6170), (3572, 3573), (8971, 8972), (3539, 3540), (6436, 7800), (7839, 7840), (1177, 159), (8100, 1693), (6473, 6474), (6273, 6274), (8676, 7201), (6816, 6817), (9847, 5912), (6202, 6203), (6098, 6099), (7546, 7547), (6588, 6589), (571, 572), (7086, 8114), (4733, 4734), (4032, 4033), (9413, 9414), (3875, 7331), (3773, 59), (8267, 5510), (5978, 5979), (1308, 1309), (5723, 7167), (1013, 1014), (350, 351), (6341, 6342), (4392, 4393), (7375, 7376), (8865, 8866), (9855, 4191), (545, 7166), (9003, 9004), (4186, 4187), (6891, 4627), (8466, 8467), (6955, 6956), (2507, 4366), (2928, 965), (4092, 4093), (3807, 1317), (158, 159), (4132, 4133), (7989, 7990), (6103, 8254), (7420, 7421), (9437, 2388), (3564, 3565), (5899, 5900), (6448, 6449), (7902, 7903), (430, 431), (4016, 4017), (9739, 5517), (6366, 3575), (7526, 7527), (7444, 4505), (1177, 1178), (6798, 4414), (7323, 9244), (1931, 1857), (9847, 2024), (4051, 2438), (2321, 2984), (2212, 2213), (56, 6799), (2932, 2933), (2674, 6311), (821, 822), (1857, 8973), (102, 103), (3941, 3942), (7506, 7507), (4836, 4837), (7917, 4051), (6000, 1809), (3999, 1032), (1308, 4627), (9702, 9703), (698, 699), (4351, 6799), (6550, 1356), (876, 6311), (2680, 1120), (1061, 9587), (8227, 8228), (6437, 4415), (7022, 7023), (7445, 4506), (5245, 5246), (1902, 1903), (9675, 5144), (2885, 2886), (1037, 853), (6551, 37), (1062, 1214), (7177, 9752), (623, 624), (3505, 5908), (8039, 6612), (3660, 3661), (2574, 3486), (4116, 5709), (8352, 9661), (887, 888), (5165, 5516), (1884, 6170), (8461, 1932), (597, 1447), (5058, 5059), (6114, 6115), (1807, 5008), (5930, 5931), (1932, 2985), (9888, 9889), (6725, 6726), (2178, 2179), (1541, 7550), (6453, 6454), (4351, 6099), (9847, 9848), (3501, 3502), (8206, 5095), (1308, 4626), (498, 6579), (4394, 4395), (3308, 3309), (3550, 3551), (597, 7294), (3112, 3113), (9839, 9840), (394, 395), (6801, 3938), (3324, 4476), (3462, 3463), (1606, 1607), (5516, 7165), (9005, 6748), (3990, 3991), (358, 359), (7962, 7963), (3767, 691), (2453, 2454), (3505, 6069), (5121, 6479), (4525, 4526), (7640, 7641), (158, 1178), (7294, 598), (6118, 1919), (2373, 4407), (8460, 3938), (1884, 4415), (7168, 7251), (6056, 6057), (875, 4367), (4348, 4349), (4475, 1717), (597, 598), (7573, 7574), (9135, 9136), (4016, 2919), (6058, 6059), (2363, 2364), (8153, 56), (2065, 2066), (1062, 3060), (4449, 4450), (9150, 9151), (2519, 2520), (570, 2574), (142, 143), (7324, 9245), (8352, 6480), (8119, 3779), (116, 3874), (522, 523), (5662, 1346), (524, 5122), (9184, 8469), (3897, 3898), (9753, 1779), (7248, 7249), (9697, 9929), (8125, 8126), (1976, 2566), (2711, 7444), (8153, 4892), (3260, 8066), (3380, 3381), (3350, 3351), (124, 7417), (1285, 2321), (5436, 5437), (7104, 7105), (1285, 6747), (3698, 3699), (6208, 6209), (1932, 4446), (2508, 4367), (56, 2560), (2558, 7444), (3945, 4210), (3748, 1062), (6551, 4407), (8001, 8002), (9678, 9679), (7304, 7305), (3962, 3963), (692, 693), (4366, 4039), (8259, 8260), (3016, 3017), (1594, 1595), (9872, 1977), (3789, 1202), (9952, 8439), (4610, 4611), (7254, 7255), (6576, 6577), (6985, 6986), (3595, 4506), (4038, 4039), (4856, 4857), (8436, 8437), (8460, 2984), (1374, 2508), (4949, 4406), (6118, 6119), (9859, 9860), (3748, 7058), (4410, 4411), (1346, 5663), (876, 4367), (7525, 9420), (6277, 6278), (7341, 8238), (1169, 1170), (1870, 3338), (8223, 8224), (9433, 9434), (2399, 2400), (5121, 9661), (5893, 7250), (876, 2507), (1037, 1038), (4756, 4757), (4099, 2853), (1304, 1305), (6443, 6728), (9856, 4191), (8461, 4051), (9718, 6423), (1308, 5296), (5122, 6480), (4662, 4663), (795, 796), (1069, 1070), (617, 618), (7681, 2502), (4350, 6099), (5214, 489), (6273, 875), (6275, 6276), (6729, 6730), (2373, 2374), (7386, 7387), (2107, 2108), (7087, 170), (201, 3152), (6801, 7918), (4774, 4775), (5141, 5142), (3543, 5449), (4170, 4171), (6437, 6798), (8209, 8210), (200, 201), (7310, 7311), (3764, 3765), (9981, 9982), (6418, 6419), (8474, 8541), (5988, 5989), (1271, 1272), (9171, 3794), (3110, 3111), (881, 1893), (1748, 3120), (5894, 5741), (3391, 4449), (3505, 1771), (6098, 56), (4350, 1885), (7445, 4505), (6951, 117), (1472, 1473), (7178, 9751), (9482, 9483), (9400, 9401), (2560, 4415), (4202, 4203), (352, 353), (3588, 3589), (4050, 8461), (876, 2508), (6616, 1073), (1213, 5717), (6098, 4415), (7015, 3594), (8461, 7917), (3789, 3790), (8438, 8439), (9077, 9078), (6992, 5516), (2419, 2420), (4474, 9829), (6311, 6274), (5406, 5407), (9528, 9529), (2573, 5866), (9821, 9822), (1031, 1032), (2816, 9929), (882, 1893), (6992, 9738), (5722, 3260), (3362, 3363), (8030, 255), (7680, 2681), (4950, 6550), (3828, 3829), (5205, 5206), (1421, 1422), (237, 6109), (8460, 6747), (4957, 4958), (5306, 7363), (7764, 7765), (9861, 9862), (591, 592), (1316, 1317), (8639, 3477), (4950, 4407), (1840, 488), (9087, 9088), (5277, 5278), (1037, 7833), (6992, 9739), (7323, 9245), (6580, 6581), (8036, 4892), (1374, 4039), (3790, 8828), (9519, 488), (9023, 9024), (1884, 1885), (2560, 6799), (2853, 7391), (2303, 2304), (4770, 5287), (4445, 2322), (6068, 6613), (4100, 4101), (876, 4250), (933, 934), (6436, 6099), (804, 883), (7528, 2919), (3560, 3561), (4445, 8461), (2985, 145), (2595, 2596), (3505, 8039), (9627, 6419), (4446, 145), (8729, 5608), (8114, 5312), (7585, 7586), (144, 2985), (881, 4120), (589, 6272), (5602, 5603), (2551, 2552), (4249, 1346), (2841, 1527), (1067, 1068), (1838, 1839), (2325, 1828), (6479, 6480), (190, 191), (5901, 5433), (100, 101), (8564, 8565), (1157, 1158), (1439, 1941), (4950, 1356), (2928, 966), (6748, 1286), (7631, 8996), (2321, 1286), (2560, 6099), (8343, 8344), (9488, 9489), (6068, 5907), (9530, 9531), (5442, 5443), (4379, 3876), (1213, 1062), (8670, 8671), (3875, 4378), (4406, 37), (1356, 37), (1854, 1855), (7086, 7087), (1135, 1136), (7323, 7324), (9002, 1811), (5227, 5228), (9587, 3060), (2676, 2677), (7696, 7697), (388, 389), (5357, 3595), (442, 443), (9626, 6419), (3505, 6613), (1893, 1453), (7680, 2502), (7550, 2933), (7948, 8541), (9212, 9213), (6857, 6858), (9244, 5671), (8695, 8696), (9447, 9448), (3171, 3172), (9036, 9899), (3072, 4210), (6922, 6923), (524, 6479), (4138, 4139), (2619, 2620), (3749, 7059), (6099, 4415)]\n",
            "\n",
            "Recall@10:\t\t92.30%\n",
            "Mean Reciprocal Rank:\t0.33954\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHhRKpknq5we"
      },
      "source": [
        "### Model 4: Cohere Sentence Embeddings --- TO BE COMPLETED\n",
        "##### <font color='red'>Expected recall@10: ~89%, MRR: ~0.34</font>\n",
        "\n",
        "Make sure create a Cohere account and make an API key.\n",
        "Compute the sentence embeddings using the cohere API and complete the `vectorize` function. Feel free to look up documentation on https://docs.cohere.ai/semantic-search. \n",
        "\n",
        "Implementation:\n",
        "\n",
        "1. Pipe the input sentences through the Cohere API. Make sure to select the small model.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COHERE_API_KEY = \"PJWSIYnprK3KBftRo9W6lSXMYyA4FRcQCWrTChjv\"\n",
        "co = cohere.Client(COHERE_API_KEY)"
      ],
      "metadata": {
        "id": "FODgVGURr2YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install limit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcSkNaiUAR1u",
        "outputId": "34b86688-3f6e-44ed-e80d-a5ee63f0b5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: limit in /usr/local/lib/python3.8/dist-packages (0.2.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnYpcV8Cq5wk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2afea2-a8e2-4a66-fba3-22a2b192414d"
      },
      "source": [
        "class CohereVectorizer:\n",
        "\n",
        "  @limit(95,60)\n",
        "  def vectorize(self, sentences):\n",
        "    \"\"\"Return sentence vectors for the batch of sentences. \n",
        "\n",
        "    1. Tokenize each sentence and create vectors for each token in the sentence\n",
        "    2. Sentence vector is the mean of word vectors of each token\n",
        "    3. Stack the sentence vectors into a numpy array using np.stack\n",
        "    \"\"\"\n",
        "\n",
        "    ### TO BE COMPLETED ###\n",
        "    sentence_vectors = co.embed(texts = sentences,\n",
        "                       model = \"small\", \n",
        "                       truncate = \"LEFT\").embeddings\n",
        "    ### TO BE COMPLETED ###\n",
        "\n",
        "    # Convert from float64 to float32 to prevent bug:\n",
        "    # https://github.com/facebookresearch/faiss/issues/461\n",
        "    return np.float32(np.stack(sentence_vectors))\n",
        "\n",
        "\n",
        "cohereIndex = FaissIndexer(sample_dataset,\n",
        "                  question_map,\n",
        "                  sample_eval_dataset,\n",
        "                  batch_size=32, \n",
        "                  sentence_vector_dim=1024, \n",
        "                  vectorizer=CohereVectorizer())\n",
        "\n",
        "cohereIndex.train_and_evaluate(question_example = \"how can i invest in stock market in india?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---- Indexing ----\n",
            "Start indexing!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 313/313 [03:08<00:00,  1.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Done indexing!\n",
            "\n",
            "---- Search ----\n",
            "Questions similar to: how can i invest in stock market in india?\n",
            "0 Question: 0 with score 2562.994140625\n",
            "1 Question: 1745 with score 2064.28125\n",
            "2 Question: 1 with score 2049.330810546875\n",
            "3 Question: 8147 with score 1887.56298828125\n",
            "4 Question: 5069 with score 1856.3853759765625\n",
            "5 Question: 1744 with score 1831.635986328125\n",
            "6 Question: 3015 with score 1825.7646484375\n",
            "7 Question: 5070 with score 1824.325439453125\n",
            "8 Question: 4906 with score 1824.1646728515625\n",
            "9 Question: 3779 with score 1807.7783203125\n",
            "\n",
            "---- Evaluation ----\n",
            "[(1600, 6886), (1930, 8973), (7218, 7219), (2994, 2995), (8599, 8600), (6311, 4366), (3594, 4506), (370, 371), (8897, 8898), (4378, 7331), (6479, 9661), (3999, 5245), (2711, 5358), (5121, 8352), (4543, 7200), (6312, 4366), (3686, 3687), (1409, 1410), (9837, 9838), (1748, 4017), (1062, 1214), (9723, 2474), (7412, 7413), (9015, 4478), (226, 227), (4445, 145), (2024, 9848), (8460, 2984), (7573, 7574), (1892, 882), (5277, 5278), (6379, 1977), (6224, 6225), (5448, 5449), (9190, 9191), (651, 107), (5374, 5375), (4445, 7841), (6128, 6129), (4445, 7918), (5508, 5509), (4184, 4185), (4070, 8553), (4445, 2985), (5554, 5555), (3766, 6063), (3958, 3959), (2066, 31), (4733, 3876), (8552, 4071), (918, 9004), (1776, 1777), (8743, 8744), (6612, 5271), (2617, 7739), (4815, 4816), (2079, 2080), (7799, 56), (9006, 7917), (2407, 2408), (4874, 4875), (3962, 3963), (1912, 1913), (8075, 8076), (3506, 6068), (3336, 3337), (7367, 7368), (5645, 5646), (9015, 4477), (3588, 3589), (4307, 4308), (4350, 6170), (4752, 4753), (3954, 3955), (1374, 4039), (1272, 9282), (8973, 8974), (4394, 4395), (7585, 7586), (7331, 3876), (8461, 4051), (7841, 2438), (8119, 3779), (6550, 6551), (3666, 9592), (4868, 4869), (642, 6720), (5473, 4925), (2375, 2376), (7331, 4379), (6748, 3938), (5051, 8243), (1308, 6891), (8051, 8052), (5894, 7168), (7524, 5635), (9702, 9519), (1931, 1857), (2291, 2292), (7294, 7295), (6483, 6484), (8022, 9916), (2420, 8827), (2323, 2324), (2846, 1373), (5893, 7251), (159, 1178), (2674, 2508), (3748, 5717), (3060, 3061), (7917, 1933), (8466, 8467), (8223, 8224), (2765, 2766), (6377, 6378), (7323, 9244), (4043, 9899), (5615, 5616), (7800, 6099), (6443, 6728), (9756, 9757), (7486, 7487), (5165, 6992), (4190, 4191), (6664, 6665), (7020, 7021), (5828, 5829), (3120, 4017), (4474, 4475), (5263, 5264), (8254, 7338), (7084, 7085), (9376, 9377), (5121, 6480), (9374, 9375), (7799, 8036), (8508, 642), (6551, 4407), (8918, 8919), (3482, 3483), (1031, 5246), (3945, 4210), (9666, 4121), (3767, 690), (2265, 2266), (4036, 7800), (7394, 7395), (6533, 6534), (524, 6479), (1213, 1214), (8153, 2560), (963, 964), (498, 499), (8811, 8437), (2853, 8013), (9902, 9903), (5312, 5313), (8039, 5908), (4259, 4260), (1309, 4627), (5740, 5893), (1806, 5009), (3595, 4506), (1237, 1238), (7015, 3594), (3350, 3351), (3775, 3776), (5901, 5433), (7949, 7950), (8936, 8937), (8081, 8082), (1231, 1232), (803, 804), (8823, 8824), (398, 1778), (1893, 1453), (633, 634), (7889, 7890), (2940, 2941), (6098, 4415), (1880, 1881), (8532, 8533), (1498, 1499), (6054, 6055), (2815, 2816), (1447, 598), (8687, 8688), (4382, 4383), (2321, 6747), (6891, 5297), (5161, 5162), (6866, 6867), (8135, 8136), (5732, 5733), (6816, 6817), (1892, 881), (1119, 7680), (881, 4121), (5756, 5757), (401, 635), (3505, 5271), (2168, 2169), (6550, 4407), (3803, 3804), (9753, 3954), (40, 41), (9855, 4191), (8890, 9342), (7013, 7014), (9710, 9711), (1556, 1557), (6437, 8036), (3749, 1214), (9739, 7165), (3374, 3375), (4752, 9596), (3862, 3863), (3046, 3047), (7086, 6541), (645, 646), (8460, 2263), (3660, 3661), (6770, 6771), (7059, 3061), (589, 590), (9413, 9414), (973, 974), (6798, 4414), (1690, 1691), (1447, 1448), (597, 7295), (7058, 1213), (8508, 8509), (3505, 6612), (9228, 9229), (8265, 8266), (200, 3151), (3992, 3993), (2785, 2786), (597, 1448), (8809, 8810), (4099, 8865), (5296, 5297), (5058, 5059), (2420, 1202), (3185, 3186), (4994, 4995), (6678, 6679), (525, 8352), (8024, 8025), (2885, 2886), (6220, 8342), (7015, 5714), (7178, 9751), (7177, 9752), (4753, 3073), (5746, 5747), (4064, 4065), (5658, 5659), (4477, 4478), (8448, 8449), (3794, 9899), (2647, 2648), (5089, 5090), (3131, 862), (9142, 9143), (1308, 4627), (5449, 6274), (4529, 4530), (4263, 4817), (5736, 5737), (7337, 6103), (2841, 1527), (3789, 8828), (3806, 1317), (917, 918), (642, 7310), (2419, 1202), (5137, 5138), (5296, 4626), (6204, 6205), (6870, 6871), (5193, 5194), (4050, 4051), (7428, 7429), (3875, 4378), (7416, 7417), (1564, 1565), (1892, 1893), (1372, 8237), (8460, 2437), (7962, 7963), (3915, 3916), (839, 840), (7985, 7986), (2487, 2488), (573, 7901), (6305, 6671), (2787, 2788), (1778, 3955), (6818, 6819), (3594, 8684), (4432, 3112), (3939, 3940), (2791, 2792), (32, 33), (8227, 8228), (6670, 6671), (2255, 2256), (2326, 1829), (3112, 3113), (9218, 9219), (4037, 1885), (7803, 7804), (9051, 9052), (3762, 3763), (4949, 4406), (2986, 2987), (1928, 1929), (144, 2438), (1654, 1655), (6503, 6504), (1291, 1125), (1748, 7528), (394, 395), (6271, 6272), (6463, 6464), (6977, 6978), (7076, 7077), (1840, 9703), (8623, 6306), (2295, 2296), (3941, 3942), (7917, 4051), (8540, 8475), (1514, 1515), (5575, 9355), (4711, 4712), (7496, 7497), (4204, 4205), (4017, 2919), (3560, 3561), (3486, 5866), (213, 4780), (8415, 8416), (5920, 5921), (876, 6311), (2676, 2677), (5635, 4629), (8578, 8579), (1910, 1911), (4036, 1885), (4350, 7800), (3612, 3613), (6416, 6417), (8827, 1201), (8958, 1008), (8884, 4051), (3259, 5723), (1375, 5448), (3937, 6747), (1119, 7681), (6481, 6482), (9429, 6028), (2656, 2657), (7086, 5313), (8460, 2321), (3998, 3999), (4978, 4979), (1886, 1887), (9348, 6978), (6479, 4549), (5109, 5110), (791, 792), (1394, 1395), (2853, 2854), (1692, 1693), (1211, 1212), (9916, 172), (1023, 1024), (3829, 7310), (7222, 7223), (3396, 3397), (5348, 5349), (6273, 1346), (6501, 6502), (7371, 7372), (4776, 4777), (3807, 1317), (2606, 1779), (1771, 6069), (2042, 2043), (5221, 5222), (6062, 6063), (1447, 7295), (8971, 8972), (350, 351), (9150, 9151), (3294, 3295), (4770, 5287), (8321, 8322), (1884, 7800), (9184, 8468), (7551, 7552), (4406, 37), (7032, 7033), (420, 421), (966, 2929), (6798, 4037), (2178, 2179), (1870, 3338), (5121, 525), (8689, 8690), (6606, 6607), (1095, 1096), (3749, 7059), (1372, 1373), (2457, 2458), (5902, 1594), (2321, 144), (2873, 2874), (2507, 4367), (9036, 9899), (319, 8238), (817, 818), (9654, 9655), (3881, 3882), (2399, 2400), (8461, 1933), (4817, 7310), (4250, 4039), (9244, 5671), (7524, 7525), (8885, 8886), (1269, 1270), (7390, 4099), (5562, 5563), (875, 4367), (3478, 3479), (500, 501), (8065, 546), (5723, 7166), (6666, 6667), (3748, 3060), (1213, 5717), (9661, 5122), (9005, 4050), (3899, 3900), (62, 63), (9916, 8023), (31, 6936), (2682, 2683), (144, 145), (1453, 4121), (7468, 7469), (3205, 3206), (7234, 7235), (5708, 5709), (2361, 2362), (5455, 574), (617, 618), (4628, 9420), (9908, 9909), (5649, 5650), (8352, 5122), (9188, 6576), (158, 1177), (6242, 6243), (8460, 6748), (1918, 6119), (3539, 3540), (7860, 319), (370, 8366), (876, 4366), (690, 6063), (4194, 4195), (326, 327), (9029, 9030), (22, 23), (7164, 7165), (4846, 4847), (5722, 5723), (5616, 3942), (9352, 3667), (7546, 7547), (2469, 2470), (3068, 3069), (1356, 6551), (1271, 9282), (9006, 4050), (2266, 7187), (58, 59), (4654, 4655), (7681, 2680), (4122, 4123), (5449, 4367), (2014, 2015), (7327, 7328), (1374, 5448), (5602, 5603), (641, 7310), (3937, 1286), (4441, 4442), (1840, 488), (6798, 6099), (9005, 8460), (8755, 8756), (5671, 9245), (1804, 1805), (5008, 5009), (6273, 2674), (3066, 3067), (5662, 1346), (6273, 875), (8574, 8575), (4880, 4881), (24, 25), (861, 3132), (8065, 7166), (7058, 1062), (9005, 4051), (8125, 8126), (9071, 9072), (2560, 8036), (2437, 3937), (5449, 4366), (1400, 1401), (3391, 4450), (7400, 7401), (171, 5313), (8460, 8884), (3748, 1062), (5986, 5987), (607, 608), (8991, 8992), (3674, 3675), (8386, 2933), (4263, 642), (8884, 3938), (1037, 8568), (2297, 2298), (6748, 1286), (6992, 5516), (7391, 8013), (8847, 8848), (5246, 1032), (9003, 917), (9872, 2566), (5744, 1182), (1852, 1853), (1292, 1293), (3795, 3796), (1285, 1286), (5522, 5523), (3541, 3542), (7947, 8541), (7001, 9004), (6373, 6374), (876, 6274), (3171, 3172), (3464, 3465), (5741, 7251), (3748, 7058), (8569, 8570), (9821, 9822), (656, 657), (330, 331), (106, 107), (1749, 4017), (7987, 7988), (8065, 3259), (1139, 1140), (6515, 6516), (4753, 9596), (9433, 9434), (7380, 7381), (1111, 1112), (5912, 2025), (7058, 5717), (6859, 6062), (9025, 9420), (59, 3774), (6366, 3574), (5213, 9702), (8123, 8124), (9848, 5912), (2501, 2680), (6951, 3874), (6554, 6555), (5717, 1214), (8254, 6679), (9856, 4191), (9352, 9353), (172, 8023), (7752, 7529), (7168, 7251), (6602, 6603), (1706, 1707), (1013, 1014), (7337, 6102), (3945, 3072), (4099, 8866), (4379, 3876), (448, 449), (1790, 1791), (876, 4250), (7525, 4629), (9364, 9365), (8461, 7917), (5786, 5787), (9184, 8469), (498, 6579), (3937, 2438), (7974, 5554), (3394, 3395), (2004, 2005), (2889, 2890), (4323, 3776), (3245, 3246), (6230, 6231), (4139, 3297), (1183, 1184), (5306, 7363), (8884, 2321), (8065, 8066), (1742, 1743), (5050, 5051), (1177, 1178), (2911, 2912), (8460, 2985), (9125, 9126), (9626, 6419), (6997, 6998), (430, 431), (4264, 6720), (8884, 2322), (1181, 2579), (1308, 4626), (7001, 918), (7341, 7342), (4351, 7800), (787, 788), (694, 695), (3901, 3902), (875, 4038), (1802, 1803), (5954, 5955), (8460, 3938), (7750, 6078), (9293, 9294), (2710, 7444), (2511, 2512), (2801, 2802), (6541, 5312), (3722, 3723), (9872, 9873), (7337, 7338), (5166, 9739), (5203, 5204), (4038, 6312), (190, 191), (8638, 8639), (6375, 6376), (9005, 2438), (8799, 4250), (2702, 2703), (6799, 4415), (6312, 2508), (1061, 3061), (2574, 3486), (3999, 1032), (1931, 8973), (4016, 2920), (6277, 6278), (6991, 5516), (1606, 1607), (3506, 5907), (8995, 7631), (9774, 9775), (4116, 5708), (5901, 5432), (6574, 6575), (9751, 9752), (2660, 2661), (9753, 2605), (1249, 1250), (8460, 8461), (3084, 3085), (6780, 6781), (5790, 5791), (8460, 6747), (7087, 171), (9011, 9012), (9171, 9898), (4050, 8461), (9723, 2473), (3340, 3341), (2321, 4051), (4738, 4739), (7947, 7948), (346, 347), (4628, 7525), (9016, 4477), (2473, 9724), (1061, 3060), (9627, 6419), (4120, 9666), (5040, 5041), (8564, 8565), (2419, 3790), (1902, 1903), (8638, 3477), (102, 103), (1062, 3061), (1632, 1633), (8239, 8400), (8039, 6612), (4770, 4771), (8001, 8002), (1061, 9587), (240, 241), (2259, 2260), (7612, 7613), (641, 4263), (2558, 2711), (3766, 3767), (6098, 8036), (2437, 7917), (3945, 3073), (5513, 2985), (7390, 2853), (6028, 9430), (545, 8066), (1748, 2919), (8857, 8858), (857, 858), (1348, 1349), (7462, 7463), (4263, 3828), (2265, 7187), (2208, 2209), (875, 6312), (1308, 5296), (561, 562), (5060, 5061), (7918, 145), (9299, 9300), (4410, 4411), (7841, 1932), (358, 359), (7901, 5455), (9764, 9765), (2938, 2939), (2227, 2228), (6473, 6474), (1976, 1977), (4628, 4629), (3391, 4449), (7294, 598), (3937, 3938), (8723, 8724), (3406, 3407), (6898, 6899), (6166, 6167), (7341, 8238), (9026, 4629), (4662, 4663), (9087, 9088), (6952, 117), (6098, 8153), (1201, 3790), (7791, 7792), (6069, 5271), (1670, 9945), (6798, 8036), (757, 758), (7997, 7998), (5856, 5857), (8799, 4366), (1091, 1092), (6580, 6581), (690, 691), (2321, 2985), (7333, 7334), (5867, 5868), (2928, 2929), (2438, 3938), (5635, 7525), (4263, 4264), (5157, 5158), (8243, 8244), (9005, 1932), (5978, 9162), (1748, 2920), (763, 764), (1884, 4037), (6550, 37), (2322, 2438), (5075, 5076), (388, 389), (9587, 1214), (8799, 2508), (7688, 7689), (4642, 4643), (4050, 2322), (9702, 488), (8039, 6613), (5988, 5989), (1308, 5297), (9494, 9495), (2321, 2984), (8995, 8996), (2387, 9437), (9595, 9596), (1027, 1028), (1067, 1068), (9021, 9022), (2065, 31), (949, 950), (8916, 8917), (9855, 9856), (7799, 4892), (7902, 7903), (1972, 1973), (7056, 7057), (9847, 2024), (288, 289), (8576, 8577), (2984, 2438), (6992, 7164), (5924, 5925), (5700, 5701), (525, 6479), (5165, 7164), (4044, 4045), (2420, 8828), (6727, 6443), (9500, 9501), (7758, 7759), (9863, 8042), (3652, 3653), (1624, 1625), (4412, 4413), (2655, 9587), (3473, 2490), (570, 5866), (7165, 5517), (5336, 5337), (5432, 5433), (6725, 6726), (58, 3774), (8240, 8400), (7799, 6799), (1594, 8118), (9825, 9170), (4517, 4518), (4523, 4524), (6430, 6431), (9630, 9631), (6436, 4037), (9243, 6890), (1594, 1595), (6471, 6472), (8022, 172), (7132, 7133), (9519, 488), (6010, 6011), (5729, 8243), (7799, 4415), (144, 2985), (1918, 1919), (3749, 5717), (5450, 3924), (3698, 3699), (4576, 4577), (9675, 5144), (6384, 6385), (4927, 4928), (4186, 4187), (8065, 3260), (5050, 147), (8067, 8068), (9001, 1810), (4660, 4661), (9170, 9171), (6739, 3472), (4822, 4823), (3789, 8827), (7185, 7186), (3505, 5908), (5002, 5003), (1356, 37), (7087, 8114), (8638, 1811), (4901, 4902), (9461, 9462), (7363, 7364), (144, 7918), (9940, 9941), (2501, 7680), (4037, 56), (2891, 6274), (8036, 4415), (6579, 499), (3828, 642), (8460, 7918), (30, 31), (3828, 7310), (4039, 4367), (5064, 5065), (4687, 4688), (5723, 7167), (58, 3773), (2419, 2420), (1177, 159), (3338, 3339), (5432, 1594), (875, 6274), (5902, 1595), (4414, 56), (418, 419), (2747, 2748), (807, 808), (8100, 1693), (171, 5312), (4733, 4734), (3308, 3309), (9592, 3667), (4178, 4179), (9006, 8461), (2891, 2892), (8891, 8892), (5099, 5100), (9587, 1062), (3155, 3156), (7390, 8013), (4037, 7800), (5166, 5516), (3476, 8639), (9129, 9130), (6992, 9739), (3348, 3349), (5265, 5266), (1235, 1236), (8468, 9185), (9006, 2322), (8482, 8483), (6264, 1272), (4378, 7332), (4151, 8980), (3749, 1213), (4048, 4049), (641, 642), (8553, 5790), (1103, 1104), (2854, 8013), (9170, 3794), (7860, 8238), (3329, 4737), (859, 860), (4524, 7831), (8257, 8258), (8055, 8056), (9795, 9796), (8294, 7154), (7201, 8677), (9256, 9257), (9242, 9243), (3594, 7444), (6220, 6221), (3874, 117), (7550, 2933), (9826, 9036), (883, 884), (4134, 4135), (9884, 9885), (8073, 8074), (7680, 2681), (1285, 3937), (5205, 5206), (4221, 4222), (3682, 3683), (2263, 6748), (9829, 966), (3793, 9899), (4961, 4962), (4727, 4728), (3562, 3563), (6747, 6748), (1347, 6312), (2710, 2711), (1576, 1577), (5357, 2711), (7445, 4505), (8430, 3393), (7681, 1120), (8607, 8608), (1516, 1517), (2903, 2904), (3151, 3152)]\n",
            "\n",
            "Recall@10:\t\t91.80%\n",
            "Mean Reciprocal Rank:\t0.34772\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onEbNcqnq5wl"
      },
      "source": [
        "🎉 CONGRATULATIONS on finishing the assignment!!! We built a real model with an actual datasets for a problem that is used every time a new Quora question gets created!! \n",
        "\n",
        "As for why did SentenceBERT & Cohere perform so well, we'll cover that in Siamese networks in week4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM0pHSbtGHuj"
      },
      "source": [
        "# Extensions\n",
        "\n",
        "Now that you've worked through the project there is a lot more for us to try:\n",
        "\n",
        "- See if you can use BERT to improve the model you shipped in Week 1.\n",
        "- Try out `SentenceBert` and `SpacyVectors` on the entire dataset rather the sample and see what you get?\n",
        "- Try different transformer models from hugging face"
      ]
    }
  ]
}